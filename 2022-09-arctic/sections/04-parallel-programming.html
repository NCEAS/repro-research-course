<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.633">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Scalable and Computationally Reproducible Approaches to Arctic Research - 4&nbsp; Pleasingly Parallel Programming</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../sections/05-adc-data-publishing.html" rel="next">
<link href="../sections/03-python-intro.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pleasingly Parallel Programming</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Course Materials</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://arcticdata.io" title="" class="sidebar-tool px-1"><i class="bi bi-house-door-fill"></i></a>
    <a href="https://twitter.com/arcticdatactr" title="" class="sidebar-tool px-1"><i class="bi bi-twitter"></i></a>
    <a href="https://github.com/NCEAS/scalable-computing-course" title="" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
</div>
    </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/01-adc-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Welcome and Introductions</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/02-remote-computing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Remote Computing</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/03-python-intro.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python Programming on Clusters</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/04-parallel-programming.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pleasingly Parallel Programming</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/05-adc-data-publishing.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Documenting and Publishing Data</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/10-geopandas.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Spatial and Image Data Using GeoPandas</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/11-parquet-arrow.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Futures: Parquet and Arrow</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../sections/references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#learning-objectives" id="toc-learning-objectives" class="nav-link active" data-scroll-target="#learning-objectives"> <span class="header-section-number">4.1</span> Learning Objectives</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"> <span class="header-section-number">4.2</span> Introduction</a></li>
  <li><a href="#why-parallelism" id="toc-why-parallelism" class="nav-link" data-scroll-target="#why-parallelism"> <span class="header-section-number">4.3</span> Why parallelism?</a></li>
  <li><a href="#processors-cpus-and-cores" id="toc-processors-cpus-and-cores" class="nav-link" data-scroll-target="#processors-cpus-and-cores"> <span class="header-section-number">4.4</span> Processors (CPUs) and Cores</a></li>
  <li><a href="#modes-of-parallelization" id="toc-modes-of-parallelization" class="nav-link" data-scroll-target="#modes-of-parallelization"> <span class="header-section-number">4.5</span> Modes of parallelization</a></li>
  <li><a href="#task-parallelism-with-concurrent.futures" id="toc-task-parallelism-with-concurrent.futures" class="nav-link" data-scroll-target="#task-parallelism-with-concurrent.futures"> <span class="header-section-number">4.6</span> Task parallelism with <code>concurrent.futures</code></a></li>
  <li><a href="#approaches-to-parallelization" id="toc-approaches-to-parallelization" class="nav-link" data-scroll-target="#approaches-to-parallelization"> <span class="header-section-number">4.7</span> Approaches to parallelization</a></li>
  <li><a href="#concurrent.futures" id="toc-concurrent.futures" class="nav-link" data-scroll-target="#concurrent.futures"> <span class="header-section-number">4.8</span> concurrent.futures</a></li>
  <li><a href="#parsl" id="toc-parsl" class="nav-link" data-scroll-target="#parsl"> <span class="header-section-number">4.9</span> parsl</a></li>
  <li><a href="#when-to-parallelize" id="toc-when-to-parallelize" class="nav-link" data-scroll-target="#when-to-parallelize"> <span class="header-section-number">4.10</span> When to parallelize</a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"> <span class="header-section-number">4.11</span> Summary</a></li>
  <li><a href="#further-reading" id="toc-further-reading" class="nav-link" data-scroll-target="#further-reading"> <span class="header-section-number">4.12</span> Further Reading</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Pleasingly Parallel Programming</span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header>

<section id="learning-objectives" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="learning-objectives"><span class="header-section-number">4.1</span> Learning Objectives</h2>
<ul>
<li>Understand what parallel computing is and when it may be useful</li>
<li>Understand how parallelism can work</li>
<li>Review sequential loops and map functions</li>
<li>Build a parallel program using <code>concurrent.futures</code></li>
<li>Build a parallel program using <code>parsl</code></li>
<li>Understand Thread Pools and Process pools</li>
</ul>
</section>
<section id="introduction" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="introduction"><span class="header-section-number">4.2</span> Introduction</h2>
<p>Processing large amounts of data with complex models can be time consuming. New types of sensing means the scale of data collection today is massive. And modeled outputs can be large as well. For example, here’s a 2 TB (that’s Terabyte) set of modeled output data from <a href="https://doi.org/10.5063/F1Z899CZ">Ofir Levy et al.&nbsp;2016</a> that models 15 environmental variables at hourly time scales for hundreds of years across a regular grid spanning a good chunk of North America:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/levy-map.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Levy et al.&nbsp;2016. doi:10.5063/F1Z899CZ</figcaption><p></p>
</figure>
</div>
<p>There are over 400,000 individual netCDF files in the <a href="https://doi.org/10.5063/F1Z899CZ">Levy et al.&nbsp;microclimate data set</a>. Processing them would benefit massively from parallelization.</p>
<p>Alternatively, think of remote sensing data. Processing airborne hyperspectral data can involve processing each of hundreds of bands of data for each image in a flight path that is repeated many times over months and years.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="../images/DataCube.png" class="img-fluid figure-img"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">NEON Data Cube</figcaption><p></p>
</figure>
</div>
</section>
<section id="why-parallelism" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="why-parallelism"><span class="header-section-number">4.3</span> Why parallelism?</h2>
<p>Much R code runs fast and fine on a single processor. But at times, computations can be:</p>
<ul>
<li><strong>cpu-bound</strong>: Take too much cpu time</li>
<li><strong>memory-bound</strong>: Take too much memory</li>
<li><strong>I/O-bound</strong>: Take too much time to read/write from disk</li>
<li><strong>network-bound</strong>: Take too much time to transfer</li>
</ul>
<p>To help with <strong>cpu-bound</strong> computations, one can take advantage of modern processor architectures that provide multiple cores on a single processor, and thereby enable multiple computations to take place at the same time. In addition, some machines ship with multiple processors, allowing large computations to occur across the entire cluster of those computers. Plus, these machines also have large amounts of memory to avoid <strong>memory-bound</strong> computing jobs.</p>
</section>
<section id="processors-cpus-and-cores" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="processors-cpus-and-cores"><span class="header-section-number">4.4</span> Processors (CPUs) and Cores</h2>
<p>A modern CPU (Central Processing Unit) is at the heart of every computer. While traditional computers had a single CPU, modern computers can ship with mutliple processors, which in turn can each contain multiple cores. These processors and cores are available to perform computations.</p>
<p>A computer with one processor may still have 4 cores (quad-core), allowing 4 computations to be executed at the same time.</p>
<p><img src="../images/processor.png" class="img-fluid"></p>
<p>A typical modern computer has multiple cores, ranging from one or two in laptops to thousands in high performance compute clusters. Here we show four quad-core processors for a total of 16 cores in this machine.</p>
<p><img src="../images/processors.png" class="img-fluid"></p>
<p>You can think of this as allowing 16 computations to happen at the same time. Theroetically, your computation would take 1/16 of the time (but only theoretically, more on that later).</p>
<p>Historically, R has only utilized one processor, which makes it single-threaded. Which is a shame, because the 2017 MacBook Pro that I am writing this on is much more powerful than that:</p>
<p><code>{bash eval=FALSE} jones@powder:~$ sysctl hw.ncpu hw.physicalcpu hw.ncpu: 8 hw.physicalcpu: 4</code></p>
<p>To interpret that output, this machine <code>powder</code> has 4 physical CPUs, each of which has two processing cores, for a total of 8 cores for computation. I’d sure like my R computations to use all of that processing power. Because its all on one machine, we can easily use <em>multicore</em> processing tools to make use of those cores. Now let’s look at the computational server <code>aurora</code> at NCEAS:</p>
<p><code>{bash eval=FALSE} jones@included-crab:~$ lscpu | egrep 'CPU\(s\)|per core|per socket' CPU(s):                88 On-line CPU(s) list:   0-87 Thread(s) per core:    2 Core(s) per socket:    22 NUMA node0 CPU(s):     0,2,4,6,8,10,12,14,16,18,20,22,24,26,28,30,32,34,36,38,40,42,44,46,48,50,52,54,56,58,60,62,64,66,68,70,72,74,76,78,80,82,84,86 NUMA node1 CPU(s):     1,3,5,7,9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59,61,63,65,67,69,71,73,75,77,79,81,83,85,87</code></p>
<p>Now that’s more compute power! <code>included-crab</code> has 384 GB of RAM, and ample storage. All still under the control of a single operating system.</p>
<p>However, maybe one of these NSF-sponsored high performance computing clusters (HPC) is looking attractive about now:</p>
<ul>
<li><a href="https://jetstream-cloud.org/">JetStream</a>
<ul>
<li>640 nodes, 15,360 cores, 80TB RAM</li>
</ul></li>
<li><a href="">Stampede2</a> at TACC is coming online in 2017
<ul>
<li>4200 nodes, 285,600 cores</li>
</ul></li>
<li>TODO: update with modern cluster sizes</li>
</ul>
<p>Note that these clusters have multiple nodes (hosts), and each host has multiple cores. So this is really multiple computers clustered together to act in a coordinated fashion, but each node runs its own copy of the operating system, and is in many ways independent of the other nodes in the cluster. One way to use such a cluster would be to use just one of the nodes, and use a multi-core approach to parallelization to use all of the cores on that single machine. But to truly make use of the whole cluster, one must use parallelization tools that let us spread out our computations across multiple host nodes in the cluster.</p>
</section>
<section id="modes-of-parallelization" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="modes-of-parallelization"><span class="header-section-number">4.5</span> Modes of parallelization</h2>
<ul>
<li>TODO: develop diagram(s) showing
<ul>
<li>Single memory image task parallelization</li>
</ul></li>
</ul>
<p>Serial <code>Launch tasks --&gt; Task 1 --&gt; Task 2 --&gt; Task 3 --&gt; Task 4 --&gt; Task 5 --&gt; Finish</code></p>
<p>Parallel <code>Launch tasks --&gt;                     Task 1 --\                    Task 2 ---\                    Task 3 -----&gt; Finish                      Task 4 ---/                     Task 5 --/</code></p>
<ul>
<li>Cluster task parallelization</li>
</ul>
<p>Cluster parallel <code>Show dispatch to cluster nodes and reassembly of data   Launch tasks --&gt;                     Marshal --&gt; Task 1 --&gt; Unmarshal --\                    Marshal --&gt; Task 2 --&gt; Unmarshal ---\                    Marshal --&gt; Task 3 --&gt; Unmarshal -----&gt; Finish                      Marshal --&gt; Task 4 --&gt; Unmarshal ---/                     Marshal --&gt; Task 5 --&gt; Unmarshal --/</code></p>
<ul>
<li>TODO: Should we also include figure with data or functional dependencies?</li>
</ul>
</section>
<section id="task-parallelism-with-concurrent.futures" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="task-parallelism-with-concurrent.futures"><span class="header-section-number">4.6</span> Task parallelism with <code>concurrent.futures</code></h2>
<p>When you have a list of repetitive tasks, you may be able to speed it up by adding more computing power. If each task is completely independent of the others, then it is a prime candidate for executing those tasks in parallel, each on its own core. For example, let’s build a simple loop that downloads the data files that we need for an analysis. First, we start with the serial implementation.</p>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use loop for serial execution of tasks</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tasks are to download data from a dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>The issue with this loop is that we execute each trial sequentially, which means that only one of our 8 processors on this machine are in use. In order to exploit parallelism, we need to be able to dispatch our tasks as functions, with one task going to each processor. To do that, we need to convert our task to a function, and then use the <code>map()</code> function to apply that function to all of the members of a set. Here’s the same code rewritten to use <code>map()</code>, which applies a function to each of the members of a list (in this case the files we want to download):</p>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use `map` for serial execution of tasks</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Tasks are to download data from a dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="approaches-to-parallelization" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="approaches-to-parallelization"><span class="header-section-number">4.7</span> Approaches to parallelization</h2>
<p>When parallelizing jobs, one can:</p>
<ul>
<li><p>Use the multiple cores on a local computer through <code>mclapply</code></p></li>
<li><p>Use multiple processors on local (and remote) machines using <code>makeCluster</code> and <code>clusterApply</code></p>
<ul>
<li>In this approach, one has to manually copy data and code to each cluster member using <code>clusterExport</code></li>
<li>This is extra work, but sometimes gaining access to a large cluster is worth it</li>
</ul></li>
</ul>
</section>
<section id="concurrent.futures" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="concurrent.futures"><span class="header-section-number">4.8</span> concurrent.futures</h2>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop versus map for parallel execution of tasks</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Using concurrent.futures and ThreadPool</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Tasks are to download data from a dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="parsl" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="parsl"><span class="header-section-number">4.9</span> parsl</h2>
<ul>
<li>Overview of parsl and it’s use of python decorators.</li>
</ul>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop versus map for parallel execution of tasks</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Using parsl decorators and ThreadPool</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Tasks are to download data from a dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>Configurable Executors in parsl
<ul>
<li>HightThroughputExecutor for cluster jobs</li>
</ul></li>
</ul>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Loop versus map for parallel execution of tasks</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Using parsl decorators and ThreadPool</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Tasks are to download data from a dataset</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="when-to-parallelize" class="level2" data-number="4.10">
<h2 data-number="4.10" class="anchored" data-anchor-id="when-to-parallelize"><span class="header-section-number">4.10</span> When to parallelize</h2>
<p>It’s not as simple as it may seem. While in theory each added processor would linearly increase the throughput of a computation, there is overhead that reduces that efficiency. For example, the code and, importantly, the data need to be copied to each additional CPU, and this takes time and bandwidth. Plus, new processes and/or threads need to be created by the operating system, which also takes time. This overhead reduces the efficiency enough that realistic performance gains are much less than theoretical, and usually do not scale linearly as a function of processing power. For example, if the time that a computation takes is short, then the overhead of setting up these additional resources may actually overwhelm any advantages of the additional processing power, and the computation could potentially take longer!</p>
<p>In addition, not all of a task can be parallelized. Depending on the proportion, the expected speedup can be significantly reduced. Some propose that this may follow <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl’s Law</a>, where the speedup of the computation (y-axis) is a function of both the number of cores (x-axis) and the proportion of the computation that can be parallelized (see colored lines):</p>
<pre><code>#| eval: false
library(ggplot2)
library(tidyr)
amdahl &lt;- function(p, s) {
  return(1 / ( (1-p) + p/s  ))
}
doubles &lt;- 2^(seq(0,16))
cpu_perf &lt;- cbind(cpus = doubles, p50 = amdahl(.5, doubles))
cpu_perf &lt;- cbind(cpu_perf, p75 = amdahl(.75, doubles))
cpu_perf &lt;- cbind(cpu_perf, p85 = amdahl(.85, doubles))
cpu_perf &lt;- cbind(cpu_perf, p90 = amdahl(.90, doubles))
cpu_perf &lt;- cbind(cpu_perf, p95 = amdahl(.95, doubles))
#cpu_perf &lt;- cbind(cpu_perf, p99 = amdahl(.99, doubles))
cpu_perf &lt;- as.data.frame(cpu_perf)
cpu_perf &lt;- cpu_perf %&gt;% gather(prop, speedup, -cpus)
ggplot(cpu_perf, aes(cpus, speedup, color=prop)) + 
  geom_line() +
  scale_x_continuous(trans='log2') +
  theme_bw() +
  labs(title = "Amdahl's Law")</code></pre>
<p>So, its important to evaluate the computational efficiency of requests, and work to ensure that additional compute resources brought to bear will pay off in terms of increased work being done. With that, let’s do some parallel computing…</p>
</section>
<section id="summary" class="level2" data-number="4.11">
<h2 data-number="4.11" class="anchored" data-anchor-id="summary"><span class="header-section-number">4.11</span> Summary</h2>
<p>In this lesson, we showed examples of computing tasks that are likely limited by the number of CPU cores that can be applied, and we reviewed the architecture of computers to understand the relationship between CPU processors and cores. Next, we reviewed the way in which traditional <code>for</code> loops in R can be rewritten as functions that are applied to a list serially using <code>lapply</code>, and then how the <code>parallel</code> package <code>mclapply</code> function can be substituted in order to utilize multiple cores on the local computer to speed up computations. Finally, we installed and reviewed the use of the <code>foreach</code> package with the <code>%dopar</code> operator to accomplish a similar parallelization using multiple cores.</p>
</section>
<section id="further-reading" class="level2" data-number="4.12">
<h2 data-number="4.12" class="anchored" data-anchor-id="further-reading"><span class="header-section-number">4.12</span> Further Reading</h2>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../sections/03-python-intro.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Python Programming on Clusters</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../sections/05-adc-data-publishing.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Documenting and Publishing Data</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>