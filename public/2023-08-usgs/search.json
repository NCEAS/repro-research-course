[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "",
    "text": "Overview"
  },
  {
    "objectID": "index.html#about-this-training",
    "href": "index.html#about-this-training",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "About this training",
    "text": "About this training\nThe NCEAS openS Program consists of three 1-week long workshops, geared towards early career researchers. Participants engage in a mix of lectures, exercises, and synthesis research activities to conduct synthesis science and implement best practices in open data science.\nopenS has been adapted to coincide with each USGS CAP training, for a total of four training sessions across 2 years."
  },
  {
    "objectID": "index.html#why-nceas",
    "href": "index.html#why-nceas",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "Why NCEAS",
    "text": "Why NCEAS\nThe National Center for Ecological Analysis and Synthesis (NCEAS), a research affiliate of the University of California, Santa Barbara, is a leading expert on interdisciplinary data science and works collaboratively to answer the world’s largest and most complex questions. The NCEAS approach leverages existing data and employs a team science philosophy to squeeze out all potential insights and solutions efficiently - this is called synthesis science.\nNCEAS has over 25 years of success with this model among working groups and environmental professionals, and we are excited to pass on this cumulative expertise to you."
  },
  {
    "objectID": "index.html#week-one-successful-synthesis-and-data-management-best-practices",
    "href": "index.html#week-one-successful-synthesis-and-data-management-best-practices",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "Week One: Successful Synthesis and Data Management Best Practices",
    "text": "Week One: Successful Synthesis and Data Management Best Practices\n\nLearning Objectives:\n\nImplement reproducible scientific workflows throughout all aspects of a project\nIncrease your familiarity and confidence with data science tools\nEffectively manage and wrangle data using tidy data practices\nAccessing, interpreting and developing metadata for synthesis research\nOrganize and initiate synthesis projects\n\n\n\nSchedule\n\n\n\n\n\n\n\n\n\nDate\nTime\nSession Title\nLead Facilitator\n\n\n\n\nMonday 08/21\nBlock 3\n1:45PM-3:15PM\nSuccessful Synthesis Science\nHalina Do-Linh, Data Training Program Manager\n\n\nTuesday 08/22\nBlock 2\n10:45AM-12:15PM\nPanel for PIs: Successful Mentorship in Synthesis Science\nHalina Do-Linh, Data Training Program Manager\n\n\nWednesday 08/23\nBlock 1\n9AM-10:30AM\nData Management Essentials\nCamila Vargas Poulsen, Data Training Coordinator"
  },
  {
    "objectID": "index.html#code-of-conduct",
    "href": "index.html#code-of-conduct",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nBy participating in this activity you agree to abide by the NCEAS Code of Conduct."
  },
  {
    "objectID": "index.html#about-this-book",
    "href": "index.html#about-this-book",
    "title": "NCEAS openS for the Climate Adaptation Postdoctoral (CAP) Fellows: Future of Aquatic Flows Cohort",
    "section": "About this book",
    "text": "About this book\nThese written materials are the result of a continuous and collaborative effort at NCEAS with the support of DataONE, to help researchers make their work more transparent and reproducible. This work began in the early 2000’s, and reflects the expertise and diligence of many, many individuals. The primary authors for this version are listed in the citation below, with additional contributors recognized for their role in developing previous iterations of these or similar materials.\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nCitation: Halina Do-Linh, Camila Vargas Poulsen. 2023. openS for USGS Climate Adaptation Postdoctoral (CAP) Fellows Program. Week One. NCEAS Learning Hub & USGS Climate Adaptation Science Centers (CASCs).\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD Additional contributors: Ben Bolker, Julien Brun, Amber E. Budden, Jeanette Clark, Samantha Csik, Carmen Galaz García, Stephanie Hampton, Natasha Haycock-Chavez, Matthew B. Jones, Samanta Katz, Julie Lowndes, Erin McLean, Bryce Mecum, Deanna Pennington, Karthik Ram, Jim Regetz, Tracy Teal, Daphne Virlar-Knight, Leah Wasser. ======= Citation: Halina Do-Linh, Carmen Galaz García, Matthew B. Jones, Camila Vargas Poulsen. 2023. Open Science Synthesis training Week 2. NCEAS Learning Hub & Delta Stewardship Council.\nAdditional contributors: Ben Bolker, Julien Brun, Amber E. Budden, Jeanette Clark, Samantha Csik, Stephanie Hampton, Natasha Haycock-Chavez, Samanta Katz, Julie Lowndes, Erin McLean, Bryce Mecum, Deanna Pennington, Karthik Ram, Jim Regetz, Tracy Teal, Daphne Virlar-Knight, Leah Wasser. &gt;&gt;&gt;&gt;&gt;&gt;&gt; 578bd0123ca53087e3afa0f2be8224cb0caa6df9\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "session_01.html#learning-objectives",
    "href": "session_01.html#learning-objectives",
    "title": "1  Successful Synthesis Science",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nProvide an overview of Logic Models\nApply the principles of Logic Models to synthesis development\nRefine synthesis group challenges"
  },
  {
    "objectID": "session_01.html#logic-models",
    "href": "session_01.html#logic-models",
    "title": "1  Successful Synthesis Science",
    "section": "1.1 Logic Models",
    "text": "1.1 Logic Models\nLogic models are a planning tool that are designed to support program development by depicting the flow of resources and processes leading to a desired result. They are also used for outcomes-based evaluation of a program and are often requested as part of an evaluation planning process by funders or stakeholders.\nA simplified logic models comprise three main parts: Inputs, Outputs and Outcomes.\n\nInputs reflect what is invested, outputs are what is done and outcomes are the results of the program.\nIn a more detailed logic model, outputs and outcomes are further broken down. Outputs are often represented as ‘Activities’ and ‘Participants’. By including participation (or participants), the logic model is explicitly considering the intended audience, or stakeholders, impacted by the program. Engagement of this audience is an output. In the case of outcomes, these can be split into short, medium and long-term outcomes. Sometimes this last category may be labeled ‘Impact’\n\nDefining the inputs, outputs and outcomes early in a planning process enables teams to visualize the workflow from activity to results and can help mitigate potential challenges. Logic models can be thought of as having an ‘if this then that’ structure where inputs -&gt; outputs -&gt; outcomes.\n\nIn the example below we have constructed a simple logic model for a hypothetical project where training materials are being developed for a group of educators to implement at their respective institutions.\n\nLinkages are not always sequential and can be within categories, bi-directional and/or include feedback loops. Detailing this complexity of relationships, or theory of action, can be time consuming but is a valuable part of the thought process for project planning. In exploring all relationships, logic modeling also allows for assessing program feasibility.\n\nThe above graphics include two sections within Outputs - Activities and Participants - and this is quite common. There is variation in logic model templates, including versions with a third type of output - “Products’. Sometimes description of these products is contained within the Activities section - for example, ‘develop curricula’, ‘produce a report’ - however calling these out explicitly is beneficial for teams focused on product development.\nProgram development (and logic modeling) occurs in response to a given ‘Situation’ or need, and exploring this is the first step in modeling. The situation defines the objective, or problem, that the program is designed to solve hence some logic models may omit the left-hand situation column but be framed with Problem and Solution statements. Finally, comprehensive logic modeling takes into consideration assumptions that are made with respect to the resources available, the people involved, or the way the program will work and also recognizes that there are external factors that can impact the program’s success.\n\nIn summary:\nLogic models support program development and evaluation and comprise three primary steps in the workflow:\n\nInputs: Resources, contributions, and investments required for a program;\nOutputs: Activities conducted, participants reached, and products produced; and\nOutcomes: Results or expected changes arising from the program structured as short-, medium- and long-term."
  },
  {
    "objectID": "session_01.html#logic-models-for-synthesis-development",
    "href": "session_01.html#logic-models-for-synthesis-development",
    "title": "1  Successful Synthesis Science",
    "section": "1.2 Logic models for synthesis development",
    "text": "1.2 Logic models for synthesis development\nLogic models are one tool for program development and have sufficient flexibility for a variety of situations, including planning for a research collaboration. While some logic model categories may feel less relevant (can we scale up to a long-term outcome from a published synthesis?), the process of articulating the research objective, proposed outcome, associated resources and activities has value. Below are examples of questions that a typical logic model (LM) will ask, and how these might be reframed for a research collaboration (RC).\nObjective/Problem Statement\nLM: What is the problem? Why is this a problem? Who does this impact?\nRC: What is the current state of knowledge? What gaps exists in understanding? Why is more information / synthesis important?\nInputs\nLM: What resources are needed for the program? Personnel, money, time, equipment, partnerships ..\nRC: What is needed to undertake the synthesis research? For personnel, think in terms of the roles that are needed - data manager, statistician, writer, editor etc. Consider the time frame. DATA - what data are needed and what already exists?\nOutputs - Activities\nLM: What will be done? Development, design, workshops, conferences, counseling, outreach..\nRC: What activities are needed to conduct the research? This could be high level or it could be broken down into details such as the types of statistical approaches.\nOutputs - Participants\nLM: Who will we reach? Clients, Participants, Customers..\nRC: Who is the target audience? Who will be impacted by this work? Who is positioned to leverage this work?\nOutputs - Products\nLM: What will you create? Publications, websites, media communications …\nRC: What research products are planned / expected? Consider this in relation to the intended audience. Is a peer-reviewed publication, report or white paper most appropriate? How will derived data be handled? Will documentation, workflows, or code be published?\nShort-term Outcomes\nLM: What short-term outcomes are anticipated among participants. These can include changes in awareness, knowledge, skills, attitudes, opinions and intent.\nRC: Will this work represent a significant contribution to current understanding?\nMedium-term Outcomes\nLM: What medium-term outcomes are predicted among participants? These might include changes in behaviors, decision-making and actions.\nRC: Will this work promote increased research activity or open new avenues of inquiry?\nLong-term Outcomes\nLM: What long-term benefits, or impacts, are expected? Changes in social, economic, civic, and environmental conditions?\nRC: Will this work result in local, regional or national policy change? What will be the long-term impact of increased investment in the ecosystem?\n\n\n\n\n\n\nBreakout: Synthesis planning with logic models\n\n\n\nBreakout groups will focus on refining ideas for synthesis topcis using the logic modeling tools described in this section. The goal for this session is to develop one or more high-level logic models that:\n\nSummarize the synthesis challenge\nDefine the inputs needed to approach the synthesis\nDefine the outputs, including activities and products that would would be needed to address the issue\nDefine the short term outcomes and longer-term impacts of the work\n\nOften it is helpful to start with a brainstorming activity to list activities and products that might be used to address the synthesis challenge, then connect those in terms of outcomes and impacts, and then circle back to the resource and data inputs needed to feed the logic model. Thinking of the whole model as a workflow can help conceptualize the dependencies among steps.\nTools:\n\nPowerpoint logic model template\nMermaid flowcharts embedded in Quarto documents\n\n\n\n\n\nflowchart LR\n    INPUTS --&gt; ACTIVITIES --&gt; OUTPUTS --&gt; OUTCOMES/IMPACTS\n\n    Scenario{{Accelerate synthesis via data science training}}\n\n    R1[Instructor] & R2[Classroom space] & R3[Projector] --&gt; B{Data Science Workshop}\n    B --&gt; C(Workshop Curriculum)\n    B --&gt; D(Presentations and Practice)\n    \n    C & D --&gt; E[/Improved Delta management/] & F[/Increased analytic efficiency/]\n\n\n\n\n\nSource\n```{mermaid}\nflowchart LR\n    INPUTS --&gt; ACTIVITIES --&gt; OUTPUTS --&gt; OUTCOMES/IMPACTS\n\n    Scenario{{Accelerate synthesis via data science training}}\n\n    R1[Instructor] & R2[Classroom space] & R3[Projector] --&gt; B{Data Science Workshop}\n    B --&gt; C(Workshop Curriculum)\n    B --&gt; D(Presentations and Practice)\n    \n    C & D --&gt; E[/Improved Delta management/] & F[/Increased analytic efficiency/]\n```"
  },
  {
    "objectID": "session_01.html#resources",
    "href": "session_01.html#resources",
    "title": "1  Successful Synthesis Science",
    "section": "1.3 Resources",
    "text": "1.3 Resources\n\nLogic model template (ppt) on Sharepoint\n\nSame Logic model template on Google Drive"
  },
  {
    "objectID": "session_02.html#learning-objectives",
    "href": "session_02.html#learning-objectives",
    "title": "2  Data Management Essentials",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nUnderstand the major components of the data life cycle and the data management plan\nPractice identifying metadata guidelines that are best for reproducibility\nBecome familiar with environmental data repositories for accessing and publishing data"
  },
  {
    "objectID": "session_02.html#the-big-idea",
    "href": "session_02.html#the-big-idea",
    "title": "2  Data Management Essentials",
    "section": "2.1 The Big Idea",
    "text": "2.1 The Big Idea\nThe ultimate goal of this lesson is to provide you with a framework to achieve open science that is FAIR, CARE, and reproducible. And while this hugely important, it is challenging in practice.\nThe framework we’ll talk about in this lesson contains the following elements:\n\nData Life Cycle\nData Management Plan (DMP)\nData ethics: FAIR and CARE Principles as a lens\nRich metadata\nMeaningful data publishing\n\nWe’ll be going over each of these elements in detail and how they each fit into the reproducible open science framework we’ve been focusing on. It’s important to note that each of these elements are all connected to each other and can be achieved and utilized simultaneously.\nWe think of this framework as a three step process:\n\nSplit your research project into meaningful steps using the Data Life Cycle\nDocument your project using a DMP\nIterate, iterate, iterate\n\nLet’s dive deeper into each of these steps now."
  },
  {
    "objectID": "session_02.html#split-your-research-project-into-meaningful-steps-using-the-data-life-cycle",
    "href": "session_02.html#split-your-research-project-into-meaningful-steps-using-the-data-life-cycle",
    "title": "2  Data Management Essentials",
    "section": "2.2 Split your research project into meaningful steps using the Data Life Cycle",
    "text": "2.2 Split your research project into meaningful steps using the Data Life Cycle\n\n2.2.1 The Data Life Cycle\nThe Data Life Cycle is a tool for facilitating successful management and preservation of data throughout a research project. Multiple versions of the data life cycle exist and vary in practice across domains or communities. For example, a meta-analysis project may only focus on the Discover, Integrate, and Analyze phases of the cycle.\n\n\n\n\n\nSource: DataOne\n\n\nDataOne’s Data Management Skillbuilding Hub offers several best practices on how to effectively work with your data throughout all stages of the data life cycle.\nA way to use the Data Life Cycle in practice is to:\n\nThink about the end goal, outcomes, and products of your project\nThink and decide steps in the Data Life Cycle you need to include in your project\nReview best practices for that step in the cycle and start outlining action items in each of those steps"
  },
  {
    "objectID": "session_02.html#document-your-project-using-a-dmp",
    "href": "session_02.html#document-your-project-using-a-dmp",
    "title": "2  Data Management Essentials",
    "section": "2.3 Document your project using a DMP",
    "text": "2.3 Document your project using a DMP\nNow let’s make these steps in the Data Life Cycle tangible using a DMP.\n\n2.3.1 Writing DMPs\nA Data Management Plan is a document that describes how you will use your data during a research project, as well as what you will do with your data long after the project ends. Often a DMP encompasses all phases of the Data Life Cycle - from planning, to collecting, to analyzing and ultimately to preservation and storage of the data.\nThese are important project aspects to deeply consider because a well-thought-out plan means you are more likely to:\n\nstay organized\nwork efficiently\ntruly share data\nengage your team\nmeet funder requirements as DMPs are becoming common in the submission process for proposals\n\nA DMP is both a straightforward blueprint for how you manage your data, and provides guidelines for your and your team on policies, access, roles, and more. While it is important to plan, it is equally important to recognize that no plan is perfect as change is inevitable. To make your DMP as robust as possible, treat it as a “living document” that you periodically review with your team and adjust as the needs of the project change.\n\n\n2.3.2 How to Plan\n\nPlan early: research shows that over time, information is lost and this is inevitable so it’s important to think about long-term plans for your research at the beginning before you’re deep in your project. And ultimately, you’ll save more time.\nPlan in collaboration: high engagement of your team and stakeholders is not only a benefit to your project, but it also makes your DMP more resilient. When you include diverse expertise and perspectives to the planning stages, you’re more likely to overcome obstacles in the future.\nUtilize existing resources: don’t reinvent the wheel! There are many great DMP resources out there. Consider the article Ten Simple Rules for Creating a Good Data Management Plan (Michener 2015), which has succinct guidelines on what to include in a DMP. Or use an online tool like DMPTool, which provides official DMP templates from funders like NSF, example answers, and allows for collaboration.\nMake revising part of the process: Don’t let your DMP collect dust after your initially write it. Make revising the DMP part of your research project and use it as a guide to ensure you’re keeping on track.\nInclude FAIR and CARE: Think of the resources we discussed in the FAIR and CARE Principles lesson. When you include FAIR and CARE in the planning process of your DMP, it will make it easier to include and maintain throughout the entire project.\n\n\n\n2.3.3 What to include in a DMP\n\n\n\n\n\n\n\nDMP Section\nGuiding Questions\n\n\n\n\nFunder Requirements\n\nDoes the funder have a template or specific DMP guidelines?\nDo you thoroughly understand all the requirements? Or do you need to reach out for clarification?\nIs there a page-limit to what you can submit in your proposal? Would it beneficial to have an appendix or a longer version of your DMP for internal use elsewhere (and not for submission)?\n\n\n\nStudy Design\n\nWhat analytical methods do you plan to use?\nWhat experiments, if any, are needed to answer your research question?\nWhat are the end products you plan to produce?\nWhat ethical considerations do you have about your project?\n\n\n\nData Collection\n\nWhat type of data do you plan to collect (text, audio files, images, models, spreadsheets)?\nWhere do you plan to source your data? Is it observational, already existing, or does it need to be collected? Do you need to obtain a license to access the data? Do you need an IRB review?\nHow much data do you plan to collect or use?\nWhat format is the data in? Is it open source or is it proprietary?\n\n\n\nData Organization\n\nHow will you manage your data? Will you be using open source or proprietary software programs?\nDo you need a database to manage your data? Are there existing databases you can utilize or do you need to build one?\nWhat software tools do you plan to use to manage and organize your data?\n\n\n\nQuality Assurance and Quality Control\n\nHow will you ensure that your data is of quality?\nHow will you maintain data integrity throughout your analysis?\nWhat tests will you run on your raw data and processed data?\nWill you be utilizing outside partners to implement testing or QA/QC measures?\n\n\n\nData Policies\n\nWhat licenses do you plan to use for your data? Are there open source licenses that meet your funders requirements?\nWhat are the policies for sharing, retaining, and licensing the data? Whose responsibility is that?\nAre there any legal or ethical restrictions on your data? Do you have sensitive data that cannot be shared? Is a metadata documentation appropriate?\n\n\n\nData documentation & Metadata\n\nWhat information is required for you and others to accurately interpret, reuse, and access your data?\nWill you be using a metadata standard?\nWhat information is needed for you to write comprehensive metadata?\nWhere and how will you maintain this documentation? Is it possible for you to have the documentation open source?\n\n\n\nData Sharing\n\nHow will the data be shared after the project ends? Is this an accessible location?\nWhen will the data and project be available? Immediately after the project ends or a time period after?\nWill you be publishing the project and the data to a journal?\nWhat data products do you plan to share?\n\n\n\nRoles and Responsibilities\n\nWho is in charge of collecting the data? Managing it? Storing it? Archiving it? Running quality control? Overall project management? There are lots of roles to consider here.\nWhat kind of expertise is needed for these roles?\nWhat happens if a role needs to change? How do you plan to handle this kind of change?\n\n\n\nLong-term Storage & Data Preservation\n\nWhere do you plan to archive your data?\nHow long will the data be accessible?\nHow will the data be accessed for future use?\nHow will you be storing the data during your project? Is this different than where you will store it after the project ends?\nDoes your institution or funder have long-term storage options for you to use?\n\n\n\nBudget\n\nDo you need to purchase any proprietary software?\nDo you need to purchase any hardware?\nDo you need to pay for any services?\nWill you need to hire employees? Consultants?\nDo you anticipate that you will need to pay for any professional development or training either for yourself or your team?"
  },
  {
    "objectID": "session_02.html#iterate-iterate-iterate",
    "href": "session_02.html#iterate-iterate-iterate",
    "title": "2  Data Management Essentials",
    "section": "2.4 Iterate, iterate, iterate",
    "text": "2.4 Iterate, iterate, iterate\nIt’s crucial to remember that a DMP is a plan. None of the information in it is set in stone and you should change and update it as needed. For example, your initial DMP may have it written to store the final datasets in a physical hard drive, but later on you find an online repository like KNB. An online data repository is a better option, and you should update your plan to reflect it!\nIt may be helpful to develop a policy where you and your team review the DMP and update it as needed. Or maybe the DMP is part of someone’s responsibility on the team, maybe it’s a rotating responsibility. There’s a lot of flexibility here, and you should implement whatever policy or plan works best for you and your collaborators.\nWhat is most important is that your DMP is an accurate reflection when you’re finished with your project so you’re ready to submit your data. This will make the process of submitting data much smoother."
  },
  {
    "objectID": "session_02.html#deep-dive-into-metadata-publishing-data",
    "href": "session_02.html#deep-dive-into-metadata-publishing-data",
    "title": "2  Data Management Essentials",
    "section": "2.5 Deep dive into Metadata & Publishing Data",
    "text": "2.5 Deep dive into Metadata & Publishing Data\nSo far we’ve discussed the high-level steps toward achieving an open science project that is FAIR, CARE, and reproducible. However, there are many sub-steps within those three steps and much of metadata and data publishing are deeply intertwined with all those steps. Meaning metadata and data publishing alone play a huge role in all aspects of the Data life cycle and DMP, so it’s worth discussing these two aspects in more detail.\n\n2.5.1 Metadata Best Practices\nMetadata (data about data) is an important part of the Data Life Cycle because it enables data reuse long after the original collection. Imagine that you’re writing your metadata for a typical researcher (who might even be you!) 30+ years from now - what will they need to understand what’s inside your data files?\nThe goal is to have enough information for the researcher to understand the data, interpret the data, and then reuse the data in another study.\n\n2.5.1.1 Overall Guidelines\nAnother way to think about metadata is to answer the following questions with the documentation:\n\nWhat was measured?\nWho measured it?\nWhen was it measured?\nWhere was it measured?\nHow was it measured?\nHow is the data structured?\nWhy was the data collected?\nWho should get credit for this data (researcher AND funding agency)?\nHow can this data be reused (licensing)?\n\n\n\n2.5.1.2 Bibliographic Guidelines\nThe details that will help your data be cited correctly are:\n\nGlobal identifier like a digital object identifier (DOI)\nDescriptive title that includes information about the topic, the geographic location, the dates, and if applicable, the scale of the data\nDescriptive abstract that serves as a brief overview off the specific contents and purpose of the data package\nFunding information like the award number and the sponsor\nPeople and organizations like the creator of the dataset (i.e. who should be cited), the person to contact about the dataset (if different than the creator), and the contributors to the dataset\n\n\n\n2.5.1.3 Discovery Guidelines\nThe details that will help your data be discovered correctly are:\n\nGeospatial coverage of the data, including the field and laboratory sampling locations, place names and precise coordinates\nTemporal coverage of the data, including when the measurements were made and what time period (ie the calendar time or the geologic time) the measurements apply to\nTaxonomic coverage of the data, including what species were measured and what taxonomy standards and procedures were followed\nAny other contextual information as needed\n\n\n\n2.5.1.4 Interpretation Guidelines\nThe details that will help your data be interpreted correctly are:\n\nCollection methods for both field and laboratory data the full experimental and project design as well as how the data in the dataset fits into the overall project\nProcessing methods for both field and laboratory samples\nAll sample quality control procedures\nProvenance information to support your analysis and modelling methods\nInformation about the hardware and software used to process your data, including the make, model, and version\nComputing quality control procedures like testing or code review\n\n\n\n2.5.1.5 Data Structure and Contents\n\nEverything needs a description: the data model, the data objects (like tables, images, matricies, spatial layers, etc), and the variables all need to be described so that there is no room for misinterpretation.\nVariable information includes the definition of a variable, a standardized unit of measurement, definitions of any coded values (i.e. 0 = not collected), and any missing values (i.e. 999 = NA).\n\nNot only is this information helpful to you and any other researcher in the future using your data, but it is also helpful to search engines. The semantics of your dataset are crucial to ensure your data is both discoverable by others and interoperable (that is, reusable).\nFor example, if you were to search for the character string “carbon dioxide flux” in a data repository, not all relevant results will be shown due to varying vocabulary conventions (i.e., “CO2 flux” instead of “carbon dioxide flux”) across disciplines — only datasets containing the exact words “carbon dioxide flux” are returned. With correct semantic annotation of the variables, your dataset that includes information about carbon dioxide flux but that calls it CO2 flux WOULD be included in that search.\n\n\n2.5.1.6 Rights and Attribution\nCorrectly assigning a way for your datasets to be cited and reused is the last piece of a complete metadata document. This section sets the scientific rights and expectations for the future on your data, like:\n\nCitation format to be used when giving credit for the data\nAttribution expectations for the dataset\nReuse rights, which describe who may use the data and for what purpose\nRedistribution rights, which describe who may copy and redistribute the metadata and the data\nLegal terms and conditions like how the data are licensed for reuse.\n\n\n\n2.5.1.7 Metadata Standards\nSo, how does a computer organize all this information? There are a number of metadata standards that make your metadata machine readable and therefore easier for data curators to publish your data.\n\nEcological Metadata Language (EML)\nGeospatial Metadata Standards (ISO 19115 and ISO 19139)\n\nSee NOAA’s ISO Workbook\n\nBiological Data Profile (BDP)\nDublin Core\nDarwin Core\nPREservation Metadata: Implementation Strategies (PREMIS)\nMetadata Encoding Transmission Standard (METS)\n\nNote this is not an exhaustive list.\n\n\n2.5.1.8 Data Identifiers\nMany journals require a DOI (a digital object identifier) be assigned to the published data before the paper can be accepted for publication. The reason for that is so that the data can easily be found and easily linked to.\nSome data repositories assign a DOI for each dataset you publish on their repository. But, if you need to update the datasets, check the policy of the data repository. Some repositories assign a new DOI after you update the dataset. If this is the case, researchers should cite the exact version of the dataset that they used in their analysis, even if there is a newer version of the dataset available.\n\n\n2.5.1.9 Data Citation\nResearchers should get in the habit of citing the data that they use (even if it’s their own data!) in each publication that uses that data.\n\n\n\n2.5.2 Publishing Data\n\n2.5.2.1 Data Sharing & Preservation\n\n\n\n2.5.2.2 Data Repositories: Built for Data (and code)\n\nGitHub is not an archival location\nExamples of dedicated data repositories:\n\nKNB\nArctic Data Center\ntDAR\nEDI\nZenodo\n\nDedicated data repositories are:\n\nRich in metadata\nArchival in their mission\nCertified\n\nData papers, e.g., Scientific Data\nre3data is a global registry of research data repositories\nRepository Finder is a pilot project and tool to help researchers find an appropriate repository for their work\n\n\n\n2.5.2.3 Data Packages\nWe define a data package as a scientifically useful collection of data and metadata that a researcher wants to preserve. Sometimes a data package represents all of the data from a particular experiment, while at other times it might be all of the data from a grant, or on a topic, or associated with a paper. Whatever the extent, we define a data package as having one or more data files, software files, and other scientific products such as graphs and images, all tied together with a descriptive metadata document.\nThese data repositories all assign a unique identifier to every version of every data file, similarly to how it works with source code commits in GitHub. Those identifiers usually take one of two forms. A DOI identifier is often assigned to the metadata and becomes a publicly citable identifier for the package. Each of the other files gets a global identifier, often a UUID that is globally unique. In the graphic to the side, the package can be cited with the DOI doi:10.5063/F1F18WN4,and each of the individual files have their own identifiers as well.\n\n\n\n\n\n2.5.2.4 DataOne Federation\nDataONE is a federation of dozens of data repositories that work together to make their systems interoperable and to provide a single unified search system that spans the repositories. DataONE aims to make it simpler for researchers to publish data to one of its member repositories, and then to discover and download that data for reuse in synthetic analyses.\nDataONE can be searched on the web, which effectively allows a single search to find data from the dozens of members of DataONE, rather than visiting each of the (currently 44!) repositories one at a time."
  },
  {
    "objectID": "session_02.html#exercise-evaluate-a-data-package-on-the-knb-repository",
    "href": "session_02.html#exercise-evaluate-a-data-package-on-the-knb-repository",
    "title": "2  Data Management Essentials",
    "section": "2.6 Exercise: Evaluate a Data Package on the KNB Repository",
    "text": "2.6 Exercise: Evaluate a Data Package on the KNB Repository\nExplore data packages published on KNB assess the quality of their metadata. Imagine you’re a data curator! The data packages you’ll be looking into more deeply are datasets you’re already familiar with through the R Practice Sessions.\n\n\n\n\n\n\nSetup\n\n\n\n\nBreak into groups and use the following data packages:\n\nGroup A: EDI Data Portal SBC LTER: Reef: Abundance, size and fishing effort for California Spiny Lobster (Panulirus interruptus), ongoing since 2012\nGroup B: EDI Data Portal Physiological stress of American pika (Ochotona princeps) and associated habitat characteristics for Niwot Ridge, 2018 - 2019\nGroup C: EDI Data Portal Ecological and social interactions in urban parks: bird surveys in local parks in the central Arizona-Phoenix metropolitan area\n\n\n\n\nYou and your group will evaluate a data package for its: (1) metadata quality, (2) data documentation quality for reproducibility, and (3) FAIRness and CAREness.\n\n\n\n\n\n\nExercise: Evaluate a data package on EDI Data Portal\n\n\n\n\nView our Data Package Assessment Rubric and make a copy of it to:\n\nInvestigate the metadata in the provided data\n\nDoes the metadata meet the standards we talked about? How so?\nIf not, how would you improve the metadata based on the standards we talked about?\n\nInvestigate the overall data documentation in the data package\n\nIs the documentation sufficient enough for reproducibility? Why or why not?\nIf not, how would you improve the data documentation? What’s missing?\n\nIdentify elements of FAIR and CARE\n\nIs it clear that the data package used a FAIR and CARE lens?\nIf not, what documentation or considerations would you add?\n\n\nElect someone to share back to the group the following:\n\nHow easy or challenging was it to find the metadata and other data documentation you were evaluating? Why or why not?\nWhat documentation stood out to you? What did you like or not like about it?\nHow well did these data packages uphold FAIR and CARE Principles?\nDo you feel like you understand the research project enough to use the data yourself (aka reproducibility?\n\n\nIf you and your group finish early, check out more datasets in the bonus question."
  },
  {
    "objectID": "session_02.html#bonus-investigate-metadata-and-data-documentation-in-other-data-repositories",
    "href": "session_02.html#bonus-investigate-metadata-and-data-documentation-in-other-data-repositories",
    "title": "2  Data Management Essentials",
    "section": "2.7 Bonus: Investigate metadata and data documentation in other Data Repositories",
    "text": "2.7 Bonus: Investigate metadata and data documentation in other Data Repositories\nNot all environmental data repositories document and publish datasets and data packages in the same way. Nor do they have the same submission requirements. It’s helpful to become familiar with metadata and data documentation jargon so it’s easier to identify the information you’re looking for. It’s also helpful for when you’re nearing the end of your project and are getting ready to publish your datasets.\nEvaluate the following data packages at these data repositories:\n\nKNB Arthropod pitfall trap biomass captured (weekly) and pitfall biomass model predictions (daily) near Toolik Field Station, Alaska, summers 2012-2016\nDataOne USDA-NOAA NWS Daily Climatological Data\nArctic Data Center Landscape evolution and adapting to change in ice-rich permafrost systems 2021-2022\n\nHow different are these data repositories from the EDI Data Portal? Would you consider publishing you data at one or multiple of these repositories?\n\n\n\n\nMichener, William K. 2015. “Ten Simple Rules for Creating a Good Data Management Plan.” PLOS Computational Biology 11 (10): 1–9. https://doi.org/10.1371/journal.pcbi.1004525."
  }
]