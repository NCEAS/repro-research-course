[["index.html", "Open Science: Best Practices, Data Sovereignty and Co-production Open Science: Best Practices, Data Sovereignty and Co-production About", " Open Science: Best Practices, Data Sovereignty and Co-production Mar 29 2022; 1600-2000 CEST Open Science: Best Practices, Data Sovereignty and Co-production About These materials reflect a collaboration between the Arctic Data Center, the Navigating the New Arctic Community Office, and ELOKA as part of our organizational commitments to raising awareness and promoting best practices in data management, increasing data literacy, and engaging the community in conversations about data governance. These materials are associated with a workshop presented as part of the Arctic Science Summit Week 2022.       Schedule This workshop is being held (online) on Tuesday March 29th at 1600 CEST, within the full ASSW programme. Agenda CEST Topic Lead 1600 Welcome and Introductions Amber Budden (Arctic Data Center) 1620 Research Reproducibility Amber Budden (Arctic Data Center) Tidy Data Best Practices Jeanette Clark (Arctic Data Center) 1700 Data Ethics Noor Johnson, Andy Barrett (NNC-CO/ ELOKA) 1730 BREAK 1745 Community Data Noor Johnson, Andy Barrett (NNC-CO/ ELOKA) 1815 Q&amp;A / Discussion Noor Johnson, Andy Barrett (NNC-CO/ ELOKA) 1830 BREAK 1845 Tidy Data and Hands-on Exercise Jeanette Clark (Arctic Data Center) 1945 Q&amp;A / Discussion Matt Jones, Jeanette Clark (Arctic Data Center) 2000 Adjourn Land Acknowledgement The circumpolar Arctic is the contemporary home to many different Indigenous Peoples. Wherever you may be participating in #ASSW2022, collectively we honor and recognize the place-based knowledge of Arctic Indigenous Peoples and their ancestral and contemporary stewardship of their homelands. In addition, we (the workshop organizers) recognize the rights of Arctic Indigenous Peoples to be involved in conversations about research related to them and their traditional territories (lands, waters, animals). We are committed to learning about how to implement Indigenous Data Sovereignty within our own institutions and in the trainings that we offer the Arctic research community. Code of Conduct Please note that by participating in this activity you agree to abide by the ASSW 2022 Code of Conduct, the NCEAS Code of Conduct, and the NNA-CO Guiding Principles. About this book These written materials reflect the continuous development of learning materials at the Arctic Data Center, NNA-Community Office and ELOKA to support individuals to understand, adopt, and apply ethical open science practices. In bringing these materials together we recognize that many individuals have contributed to their development. The primary authors are listed alphabetically in the citation below, with additional contributors recognized for their role in developing previous iterations of these or similar materials. This work is licensed under a Creative Commons Attribution 4.0 International License. Citation: Andrew Barrett, Amber E. Budden, S. Jeanette Clark, Natasha Haycock-Chavez, Noor Johnson, Matthew B. Jones. 2022. Open Science: Best Practices, Data Sovereignty and Co-production. Additional contributors: Stephanie Hampton, Jim Regetz, Bryce Mecum, Julien Brun, Julie Lowndes, and Erin McLean. "],["session-1-open-science-best-practices.html", "1 Session 1: Open Science Best Practices 1.1 Introduction to Reproducible Research 1.2 Tidy Data: Part 1 1.3 Open Data Ethics 1.4 Community Data", " 1 Session 1: Open Science Best Practices 1.1 Introduction to Reproducible Research 1.1.0.1 What is research reproducibility and how does it relate to open science? Reproducibility is a hallmark of scientific research, which is based on empirical observations coupled with explanatory models. Whether integrating data from across multiple studies and sources, or working with your own data, the data life cycle typically involves some degree of data collection/integration, quality assurance practices, analysis and synthesis. Operating in a reproducible fashion means that each of these steps can be easily re-executed to achieve the same result, ideally as part of a single workflow. Reproducibility means different things to different researchers. For our purposes, practical reproducibility looks like: - Preserving the data - Preserving the software workflow - Documenting what you did - Describing how to interpret it all Reproducibility does not, by definition, require openness. Reproducibility can be achieved within a single research activity or across a research program with a closed group of collaborators. However, when working in an OPEN and REPRODUCIBLE manner, we are better able to transform knowledge into benefits for society. In this section we will expand on the benefits of reproducible research and open science before highlighting some best practices. Why is reproducible research important? Working in a reproducible manner builds efficiencies into your own research practices. The ability to automate processes and rerun analyses as you collect more data, or share your full workflow (including data, code and products) with colleagues, will accelerate the pace of your research and collaborations. However, beyond these direct benefits, reproducible research builds trust in science with the public, policy makers and others. What data were used in this study? What methods applied? What were the parameter settings? What documentation or code are available to us to evaluate the results? Can we trust these data and methods? Are the results reproducible? Ionnidis (2005) contends that “Most research findings are false for most research designs and for most fields”, and a study of replicability in psychology experiments found that “Most replication effects were smaller than the original results” (Open Science Collaboration, 2015). In the case of ‘climategate’, it took three years, and over 300 personnel, to gather the necessary provenance information in order to document how results, figures and other outputs were derived from input sources. Time and effort that could have been significantly reduced with appropriate documentation and reproducible practices. Moving forward, through reproducible research training, practices, and infrastructure, the need to manually chase this information will be reduced enabling replication studies and great trust in science. 1.1.0.2 Open Science To enable full reproducibility by the broader community; researchers, practitioners, policy makers etc, all products of the research activity need to be accessible - open data, open code, and open publications. Further, full research transparency also requires open peer review. There are, of course, data sensitivities and ethical considerations regarding open everything and these will be discussed later. At its core, the aims of Open Science are to: 1. Increase transparency of the research process 1. Enable reproducibility of results and conclusions 1. Accelerate Discovery 1. Enhance and facilitate collaboration 1. Increase diversity, equity and inclusion 1. Transform knowledge into benefits for society Computational reproducibility Computational reproducibility is the ability to document data, analyses, and models sufficiently for other researchers to be able to understand and ideally re-execute the computations that led to scientific results and conclusions. To be able to evaluate the data, analyses, and models on which conclusions are drawn, computational reproducibility requires open science approaches, including straightforward steps for archiving data and code openly along with the scientific workflows describing the provenance of scientific results (e.g., Hampton et al. (2015), Munafò et al. (2017)). Scientific workflows encapsulate all of the steps from data acquisition, cleaning, transformation, integration, analysis, and visualization. Workflows can range in detail from simple flowcharts to fully executable scripts. R scripts and python scripts are a textual form of a workflow, and when researchers publish specific versions of the scripts and data used in an analysis, it becomes far easier to repeat their computations and understand the provenance of their conclusions. Computational reproducibility provides: transparency by capturing and communicating scientific workflows research to stand on the shoulders of giants (build on work that came before) credit for secondary usage and supports easy attribution increased trust in science Preserving computational workflows enables understanding, evaluation, and reuse for the benefit of future you and your collaborators and colleagues across disciplines. 1.2 Tidy Data: Part 1 1.2.1 Learning Objectives Understand basics of relational data models aka tidy data Learn how to design and create effective data tables 1.2.2 Introduction In this lesson we are going to learn what relational data models are, and how they can be used to manage and analyze data efficiently. Relational data models are what relational databases use to organize tables. However, you don’t have to be using a relational database (like mySQL, MariaDB, Oracle, or Microsoft Access) to enjoy the benefits of using a relational data model. Additionally, your data don’t have to be large or complex for you to benefit. Here are a few of the benefits of using a relational data model: Powerful search and filtering Handle large, complex data sets Enforce data integrity Decrease errors from redundant updates Simple guidelines for data management A great paper called ‘Some Simple Guidelines for Effective Data Management’ (Borer et al. 2009) lays out exactly that - guidelines that make your data management, and your reproducible research, more effective. Use a scripted program (like R!) A scripted program helps to make sure your work is reproducible. Typically, point-and-click actions, such as clicking on a cell in a spreadsheet program and modifying the value, are not reproducible or easily explained. Programming allows you to both reproduce what you did, and explain it if you use a tool like Rmarkdown. Non-proprietary file formats are preferred (eg: csv, txt) Using a file that can be opened using free and open software greatly increases the longevity and accessibility of your data, since your data do not rely on having any particular software license to open the data file. Keep a raw version of data In conjunction with using a scripted language, keeping a raw version of your data is definitely a requirement to generate a reproducible workflow. When you keep your raw data, your scripts can read from that raw data and create as many derived data products as you need, and you will always be able to re-run your scripts and know that you will get the same output. Use descriptive file and variable names (without spaces!) When you use a scripted language, you will be using file and variable names as arguments to various functions. Programming languages are quite sensitive with what they are able to interpret as values, and they are particularly sensitive to spaces. So, if you are building reproducible workflows around scripting, or plan to in the future, saving your files without spaces or special characters will help you read those files and variables more easily. Additionally, making file and variables descriptive will help your future self and others more quickly understand what type of data they contain. Include a header line in your tabular data files Using a single header line of column names as the first row of your data table is the most common and easiest way to achieve consistency among files. Use plain ASCII text ASCII (sometimes just called plain text) is a very commonly used standard for character encoding, and is far more likely to persist very far into the future than proprietary binary formats such as Excel. The next three are a little more complex, but all are characteristics of the relational data model: Design tables to add rows, not columns Each column should contain only one type of information Record a single piece of data only once; separate information collected at different scales into different tables. 1.2.3 Recognizing untidy data Before we learn how to create a relational data model, let’s look at how to recognize data that does not conform to the model. Data Organization This is a screenshot of an actual dataset that came across NCEAS. We have all seen spreadsheets that look like this - and it is fairly obvious that whatever this is, it isn’t very tidy. Let’s dive deeper in to exactly why we wouldn’t consider it tidy. Multiple tables Your human brain can see from the way this sheet is laid out that it has three tables within it. Although it is easy for us to see and interpret this, it is extremely difficult to get a computer to see it this way, which will create headaches down the road should you try to read in this information to R or another programming language. Inconsistent observations Rows correspond to observations. If you look across a single row, and you notice that there are clearly multiple observations in one row, the data are likely not tidy. Inconsistent variables Columns correspond to variables. If you look down a column, and see that multiple variables exist in the table, the data are not tidy. A good test for this can be to see if you think the column consists of only one unit type. Marginal sums and statistics Marginal sums and statistics also are not considered tidy, and they are not the same type of observation as the other rows. Instead, they are a combination of observations. 1.3 Open Data Ethics Developed by the Exchange for Local Observations and Knowledge of the Arctic (ELOKA) and Navigating the New Arctic Community Office (NNA-CO). 1.3.0.1 Introduction This part of the training offers an introduction to ethics in the context of open science. It was developed with input from ELOKA and the NNA-CO, and is a work-in-progress – this is the first time we are offering this training. The training introduces ethics issues in a broad way and includes discussion of social science data and open science, but the majority of the section focuses on issues related to research with, by, and for Indigenous communities. We recognize that there is a need for more in-depth training and focus on open science for social scientists and others who are not engaging with Indigenous Knowledge holders and Indigenous communities, and hope to develop further resources in this area in the future. Many of the data stewardship practices that have been identified as good practices through Indigenous Data Sovereignty framework development are also relevant for those working with Arctic communities that are not Indigenous, although the rights frameworks and collective ownership is specific to the Indigenous context. The examples we include in this training are primarily drawn from the North American research context. In future trainings, we plan to expand and include examples from other Indigenous Arctic contexts. We welcome suggestions and resources that would strengthen this training for audiences outside of North America. We also recognize the importance of trainings on Indigenous data sovereignty and ethics that are being developed and facilitated by Indigenous organizations and facilitators. In this training we offer some introductory material but there is much more depth offered in IDS specific trainings. We include some suggestions of organizations offering further training in the “resources” section and encourage participants to seek out these opportunities to deepen their understanding. 1.3.0.2 Equity issues in open science Arctic communities (defined based on geographic location in the Arctic/sub-Arctic) are involved in research in diverse ways - as hosts to visiting or non-local researchers, as well as “home” to community researchers who are leading or collaborating on research projects. Over the past decades, community voices of discontent with standard research practices that are often exclusive and perpetuate inequities have grown stronger. The Arctic research community (defined more broadly as the range of institutions, organizations, researchers and local communities involved in research) is in the midst of a complex conversation about equity in research aimed at transforming research practice to make it more equitable and inclusive. One of the drivers of community concerns is the colonial practice of extracting knowledge from a place or group of people without respect for local norms of relationship with people and place and without an ethical commitment to sharing and making benefits of knowledge accessible and accountable to that place. Such approaches to knowledge and data extraction follow hundreds of years of exploration and research that viewed science as a tool of “Enlightenment” yet focused exclusively on benefits to White, European (or “southern” from an Arctic community perspective) researchers and scientists. This prioritization of non-local perspectives and needs (to Arctic communities) continues in Arctic research. Open science is ostensibly about making access to data and knowledge more equitable and open and enabling reproducible research. Because it is being implemented within a social and institutional context that continues to perpetuate inequities in research, however, there are significant challenges remaining to ethically and equitably implementing open science practices. Here are some examples: Many Open Science tools and practices (e.g. GitHub, non-proprietary software) have been adopted from software development, and are not familiar to many, even physical, scientists. This makes barriers to implementation of open science and participation in open science practices higher for some than for others. Some of the main focus areas of open science (making sure data is archived in a clean and reusable format, open access publication) are still not accessible for Arctic residents and others who are not already situated within an academic environment. Open science assumes access to tools and infrastructure, such as computers that have reliable and low-cost or subsidized internet access. These structural inequalities extend even within the academy. Researchers and academics based in lower-income countries have fewer provided resources and sources of support to pay for open access fees and face greater challenges in adopting open science practices. The emphasis of open science on stakeholder and rights holder engagement and knowledge co-production also creates unintended challenges for Arctic communities. For example, when the National Science Foundation’s Navigating the New Arctic initiative, which brought millions of additional funds to Arctic research, suggested that research projects incorporate co-production and collaboration with Arctic communities, community representatives reported being inundated with requests from researchers. Perhaps because NNA was designed, in part, to bring new researchers and disciplines into Arctic research, many of these requests were made without adequate regard for recognized good practices for community engagement (such as the importance of building relationships, reaching out very early for input; communicating “early and often;” and incorporating significant resources for community participants’ time and knowledge into project budgets, among other things). As a letter to NSF written by Kawerak, the Association of Village Council Presidents, the Aleut Community of St. Paul Island, and the Bering Sea Elders Group emphasized, without adequate attention to these practices as well as an emphasis on topics that communities have identified as important, research will not serve community partners and will fail to achieve its broader impact goals. (See also the 2021 update letter from the same organizations). 1.3.0.3 Social science and open data In addition to these equity related challenges in promoting open access, there are also different disciplinary norms and requirements that can create challenges for the adoption of open science practices. For example, traditional social science methods training and IRB processes emphasize confidentiality and privacy. Social scientists generally lack access to training about benefits of sharing data. On the other hand, social scientists are often trained to be attuned to issues of equity and access, including issues related to information equity. Those who lack this background may not give adequate attention or time to the process of partnering with communities. The Arctic Horizons Report reviewed challenges around social science data management. In 2020, a workshop organized by the Arctic Data Center reviewed some of the challenges for sharing and reusing social science data, including: Data heterogeneity, including “unstructured” data that is not always well supported by data repositories; A dearth of metadata support for social sciences, with repositories not always offering relevant metadata fields; A lack of “formal vocabularies” that limits findability of social science data in searches; Limited training and support in data management practices for social scientists; limited examples using social science data in interdisciplinary trainings. In addition to these challenges, a number of broader concerns about sharing data were identified, including: Concerns about proper handling of sensitive data; importance of upholding IRB and ethics requirements, data sharing/use agreements; Importance of context - researchers may feel that data reuse is too difficult given lack of contextual knowledge; Concerns about upholding Indigenous data sovereignty. 1.3.0.4 Open (and other) data challenges for Indigenous Peoples The introduction of open data requirements has raised concerns about how open data objectives such as making data freely available for use and reuse may conflict with Indigenous Data Sovereignty and the right of Indigenous peoples to govern their data (Rainie et al. 2019: 301). Stephanie Carroll (formerly Rainie) and colleagues (2019) have summarized some of the data challenges for Indigenous Peoples, including: Data collection invisibility and bias Insufficient involvement of Indigenous Peoples in broader decisions/discussions about data governance, including decisions about what data is collected, when, how, and by whom, as well as involvement in global data governance bodies. Even if Indigenous peoples are not part of data collection, if the data is collected on Indigenous lands and could be used to support decisions that impact these lands, animals, or Indigenous peoples, they should be part of decision-making about that data. Data access, use, and interpretation, including: Insufficient availability of data about Indigenous peoples - gaps in national data collection Challenges in data access (infrastructure and training) Data collected from a “deficit” lens - reinforces perception of dysfunction, leading to bias and misrepresentation. Open data movement prioritizes making data available for reuse. However, there are concerns about secondary analysis of Indigenous data given the importance of context to understanding/interpreting Indigenous data and emphasis on building and maintaining relationships to Indigeous research (Burrage 2021). Important for researchers generating data that they hope will be useful to Indigenous communities to be aware of ethical frameworks for working with/sharing data and partnering with communities. Data ownership and appropriation Digitization of data/“big data” - the context surrounding data is often very important to Indigenous Knowledge and data. The digitization of data raises concerns about how and to what extent this context can be preserved. Individual vs. collective rights. Data ownership is often focused on individual rights (both in protection of sensitive data as well as in intellectual property rights), while Indigenous peoples have both individual and collective rights in relation to data. All requests for data contributions, clarification, or informational resources are requests for collaboration and should be treated with the same level of importance as larger projects (Murphy 2019). 1.3.0.5 The role of IRBs and Indigenous data In the United States, Institutional Review Boards (IRBs; in Canada they are referred to as Research Ethics Boards or REBs) focus on ensuring ethical treatment and protection of research subjects with a particular focus on vulnerable populations and ethical management of data. For projects proposing research that involves Indigenous peoples in the United States, IRBs will often refer the review to Tribal IRBs, which are research review boards established and implemented directly by Tribal Nations. Tribal IRBs reflect and respond to community needs, changes in research, and revisions to research policy (Around Him et al. 2019). Oversight mechanisms range from federally registered review bodies and policy development to community-specific frameworks and approaches (see Around Him et al. 2019 for differentiation, justification and authority). In addition to IRB review, universities require ethics training for researchers who are doing research with human subjects, including Indigenous Peoples. Many universities use the web-based, third-party CITI training program, which offers different short courses. A basic training course for social and behavioral science researchers covers the history of ethical misconduct in research, how human subjects research is defined, federal regulations that govern research practice, assessing risk, informed consent, privacy and confidentiality, and ethics requirements for different categories of vulnerable populations including prisoners and children. While the CITI human subjects trainings touch on topics related to Indigenous peoples, they are not at all comprehensive. A CITI webinar, “Research with Native American Communities: Important Considerations when Applying Federal Regulations” introduces more topics. The r-ETHICS training (Ethics Training for Health in Indigenous Communities Study) is starting to become an acceptable, recognizable CITI addition for IRB training by tribal entities. Specific universities have adopted tribal consultation policies (such as the Arizona Board of Regents’ (ABOR) Tribal Consultation policy (1-118) adopted in 2016; University of Wisconsin System Board of Regents tribal consultation policy adopted in 2021; Washington State University EP 41 adopted in 2021). These policies highlight where consultation is expected/required and what the process should be (Marley 2019). In Canada, funding agencies have established the Tri-Council Policy Statement on Ethical Conduct for Research Involving Humans; Chapter 9 focuses on research involving First Nations, Inuit and Metis. The chapter points to the importance of addressing issues regarding access to data and use of data with involved communities and suggests using a research agreement to establish any limits on data use and sharing, provisions to offer the opportunity for research participants and collaborators to review reports and publications prior to dissemination/publication, and to include provisions for any anticipated secondary use of information. The Tri-Council Statement has resulted in direct modifications to institutional-level REB (Canada) processes and procedures, such as incorporation of dedicated sections focusing on Indigenous research ethics within University protocols. For example, the “Indigenous Peoples and Community Engagement” section of an REB application at a Canadian university asks researchers to “Describe arrangements for the participating community’s/ies’ ownership and/or sharing of project data and findings, including the OCAP principles.” 1.3.0.6 Indigenous data governance and sovereignty All governing entities, whether national, state, local, or tribal, need access to good, current, relevant data in order to make policy, planning, and programmatic decisions. Indigenous nations and organizations have had to push for data about their peoples and communities to be collected and shared in ethical and culturally appropriate ways, and they have also had to fight for resources and capacity to develop and lead their own research programs. Indigenous data definitions: Indigenous data sovereignty “…refers to the right of Indigenous peoples to govern the collection, ownership, and application of data about Indigenous communities, peoples, lands, and resources (Rainie et al. 2019). These governance rights apply “regardless of where/by whom data is held (Rainie et al. 2019). Some Indigenous individuals and communities have expressed dissatisfaction with the term “data” as being too narrowly focused and abstract to represent the embedded and holistic nature of knowledge in Indigenous communities. Knowledge sovereignty is a related term that has a similar meaning but is framed more broadly, and has been defined as: “Tribal communities having control over the documentation and production of knowledge (such as through research activities) which relate to Alaska Native people and the resources they steward and depend on” (Kawerak 2021). Indigenous data is “data in a wide variety of formats inclusive of digital data and data as knowledge and information. It encompasses data, information, and knowledge about Indigenous individuals, collectives, entities, lifeways, cultures, lands, and resources.” (Rainie et al. 2019) Indigenous data governance is “The entitlement to determine how Indigenous data is governed and stewarded” (Rainie et al. 2019) 1.3.0.7 IDS Frameworks There has been increasing emphasis on development of frameworks to support ethical research and data stewardship grounded in Indigenous understandings and world views. The emergence of national and global networks focusing on Indigenous data sovereignty has supported the development of some of these frameworks. For example, the Global Indigenous Data Alliance (GIDA) developed the CARE principles in response to the emergence of the FAIR principles. CARE is a set of high-level principles that are broad enough to encompass more specific frameworks and principles developed by International and national Indigenous networks, organizations, and Tribes. This alliance is supported by three national networks, the United States Indigenous Data Sovereignty Network (USIDSN), Te Mana Raraunga Maori Data Sovereignty Network, and the Maiam nayri Wingara Aboriginal and Torres Strait Islander Data Sovereignty Collective. The latter networks each have worked within their respective national contexts to develop IDS principles at a “mid-level.” These frameworks are being developed at different governance levels, from “high level” frameworks that are global in scale and therefore more general to mid-level frameworks that are developed at a national scale or by a subset of Indigenous Peoples/Nations (such as circumpolar Inuit or Inuit within the national level in Canada), to foundational level frameworks that are developed at the Tribal or community scale. It is important for researchers to be aware of the different frameworks that can inform and guide ethical research practice and data management. Frameworks developed at the high or mid-level do not replace foundational frameworks. In the absence of a written framework at the tribal/community scale, the practices of strong consultation and engagement outlined in mid-level frameworks can help inform the development of an ethical approach. High level frameworks in support of IDS: The UN Declaration on the Rights of Indigenous Peoples, which recognizes the collective rights of Indigenous peoples. Article 18 of UNDRIP recognizes the right of Indigenous Peoples to participate in decision-making about matters that affect their rights; Article 19 recognizes the requirement for states to consult and cooperate with Indigenous Peoples to gain their Free Prior and Informed Consent on legislation that affects them. Other international protocols such as Nagoya Protocol on access and benefit sharing and the Cartagena Protocol on biosafety (UNCBD) also recognize Indigenous rights with reference to intellectual property and the right to benefit from Indigenous knowledge and data as the owners/stewards of that data. CARE principles were developed by — to accompany the FAIR Principles and guide their implementation in relation to Indigenous data in a way that is “people and purpose oriented.” The CARE Principles stand for: Collective Benefit - Data ecosystems shall be designed and function in ways that enable Indigenous Peoples to derive benefit from the data for: Inclusive development/innovation Improved governance and citizen engagement Equitable outcomes Authority to Control - Indigenous Peoples’ rights and interests in Indigenous data must be recognised and their authority to control such data be empowered. Indigenous data governance enables Indigenous Peoples and governing bodies to determine how Indigenous Peoples, as well as Indigenous lands, territories, resources, knowledges and geographical indicators, are represented and identified within data. Recognizing Indigenous rights (individual and collective) and interests Data for governance Governance of data Responsibility - Those working with Indigenous data have a responsibility to share how those data are used to support Indigenous Peoples’ self-determination and collective benefit. Accountability requires meaningful and openly available evidence of these efforts and the benefits accruing to Indigenous Peoples. For positive relationships For expanding capability and capacity (enhancing digital literacy and digital infrastructure) For Indigenous languages and worldviews (sharing data in Indigenous languages) Ethics - Indigenous Peoples’ rights and wellbeing should be the primary concern at all stages of the data life cycle and across the data ecosystem. Minimizing harm/maximizing benefit - not using a “deficit lens” that conceives of and portrays Indigenous communities as dysfunctional, lacking solutions, and in need of intervention. For researchers, adopting a deficit lens can lead to collection of only a subset of data while excluding other data and information that might identify solutions, innovations, and sources of resilience from within Indigenous communities. For policy makers, a deficit lens can lead to harmful interventions framed as “helping.” For justice - addressing power imbalances and equity For future use - acknowledging potential future use/future harm. Metadata should acknowledge provenance and purpose and any limitations in secondary use inclusive of issues of consent. The CARE principles were developed in relation to the FAIR principles to add an ethical framework for open data, as expressed in the phrase #BeFAIRandCARE. Although they focus on Indigenous data, they are broadly relevant to other types of data, recognizing the rights of different communities to control and access data by/for/about them (Carroll et al., 2021). Complementarity and disconnect between the FAIR and CARE principles and Open Data Charter have been discussed by participants in the open data community (Stone &amp; Calderon 2019). While FAIR and CARE are complementary, CARE has some overlap with the ODC as well as a point of tension in relation to the ODC value of making data “open by default” (Carroll et al. 2020). Stephanie Carroll and colleagues suggest that the implementation of CARE can help clarify and refine the intent of “open by default,” which could be defined in a way that also upholds Indigenous data rights (Carroll et al. 2020). Mid-level frameworks: OCAP (ownership, control, access, possession - First Nations) Inuit Circumpolar Council’s Ethical and Equitable Engagement Synthesis National Inuit Strategy on Research Maori IDSov Maiam nayri Wingara key principles Foundational level frameworks: Tribal or community-level expectations/frameworks - such as Native Village of Kotzebue’s Research Protocol (Whiting 2022), which requests that researchers follow ethical research practices pertaining to informed consent and: Inform the Tribe of plan to research and continue to inform them after permission has been granted; Consult with the Tribe in project development, implementation and planning. Explain the purposes, goals, time frame, and methodology of the research, including the sponsoring institutions and affiliations of the research project and identify the person in charge, as well as all investigators involved in the research, and the need for consultants, guides, or interpreters and proposed compensation rates for same Share results with the Tribe in non-technical language Give credit to those contributing to the research project by acknowledging the Intellectual Property Rights of individual Tribal citizens taking part in the research (unless there are requirements for anonymity) Recognize that all information belongs to the Tribe and divulgence of such information is expressly forbidden without permission of the Tribe; Compensate Indigenous Knowledge holders fairly for sharing their knowledge. 1.3.0.8 Discussion questions: For those of you who do work with Indigenous Arctic communities, (how) have the ethical norms and practices/requirements for data management changed during the period of your research? What impacts have you seen from these changes? How can funders and Arctic research/science support organizations and bodies (such as IASC) make it easier for researchers to uphold and implement Indigenous data sovereignty? 1.4 Community Data References "],["session-2-data-tidying.html", "2 Session 2: Data Tidying 2.1 Tidy Data: Part 2", " 2 Session 2: Data Tidying 2.1 Tidy Data: Part 2 2.1.1 Good enough data modeling Denormalized data When data are “denormalized” it means that observations about different entities are combined. In the above example, each row has measurements about both the community in which observations occurred, as well as observations of two individuals surveyed in that community. This is not normalized data. People often refer to this as wide format, because the observations are spread across a wide number of columns. Note that, should one survey another individual in either community, we would have to add new columns to the table. This is difficult to analyze, understand, and maintain. Tabular data Observations. A better way to model data is to organize the observations about each type of entity in its own table. This results in: Separate tables for each type of entity measured Each row represents a single observation within that entity Observations (rows) are all unique This is normalized data (aka tidy data) Variables. In addition, for normalized data, we expect the variables to be organized such that: All values in a column are of the same type All columns pertain to the same observed entity (e.g., row) Each column represents either an identifying variable or a measured variable Challenge Try to answer the following questions: What are the observed entities in the example above? What are the measured variables associated with those observations? Answer: If we use these questions to tidy our data, we should end up with: one table for each entity observed one column for each measured variable additional columns for identifying variables (such as community) Here is what our tidy data look like: Note that this normalized version of the data meets the three guidelines set by (Borer et al. 2009): Design tables to add rows, not columns Each column should contain only one type of information Record a single piece of data only once; separate information collected at different scales into different tables. 2.1.2 Using normalized data Normalizing data by separating it into multiple tables often makes researchers really uncomfortable. This is understandable! The person who designed this study collected all of this information for a reason - so that they could analyze it together. Now that our community and survey information are in separate tables, how would we use population as a predictor variable for language spoken, for example? The answer is keys - and they are the cornerstone of relational data models. When one has normalized data, we often use unique identifiers to reference particular observations, which allows us to link across tables. Two types of identifiers are common within relational data: Primary Key: unique identifier for each observed entity, one per row Foreign Key: reference to a primary key in another table (linkage) Challenge In our normalized tables above, identify the following: the primary key for each table any foreign keys that exist Answer The primary key of the top table is community. The primary key of the bottom table is id. The community column is the primary key of that table because it uniquely identifies each row of the table as a unique observation of a community. In the second table, however, the community column is a foreign key that references the primary key from the first table. Entity-Relationship Model (ER) An Entity-Relationship model allows us to compactly draw the structure of the tables in a relational database, including the primary and foreign keys in the tables. In the above model, one can see that each community in the community observations table must have one or more survey participants in the survey table, whereas each survey response has one and only one community. Merging data Frequently, analysis of data will require merging these separately managed tables back together. There are multiple ways to join the observations in two tables, based on how the rows of one table are merged with the rows of the other. When conceptualizing merges, one can think of two tables, one on the left and one on the right. The most common (and often useful) join is when you merge the subset of rows that have matches in both the left table and the right table: this is called an INNER JOIN. Other types of join are possible as well. A LEFT JOIN takes all of the rows from the left table, and merges on the data from matching rows in the right table. Keys that don’t match from the left table are still provided with a missing value (na) from the right table. A RIGHT JOIN is the same, except that all of the rows from the right table are included with matching data from the left, or a missing value. Finally, a FULL OUTER JOIN includes all data from all rows in both tables, and includes missing values wherever necessary. Sometimes people represent these as Venn diagrams showing which parts of the left and right tables are included in the results for each join. These however, miss part of the story related to where the missing value come from in each result. In the figure above, the blue regions show the set of rows that are included in the result. For the INNER join, the rows returned are all rows in A that have a matching row in B. 2.1.3 Data modeling exercise Break into groups, 1 per table Our funding agency requires that we take surveys of individuals who complete our training courses so that we can report on the demographics of our trainees and how effective they find our courses to be. In your small groups, design a set of tables that will capture information collected in a participant survey that would apply to many courses. Don’t focus on designing a comprehensive set of questions for the survey, one or two simple stand ins (eg: “Did the course meet your expectations?”, “What could be improved?”, “To what degree did your knowledge increase?”) would be sufficient. Include as variables (columns) a basic set of demographics and identifying information, such as career stage, date of birth, gender, name, and contact information. Draw your entity-relationship model in the invision session for your group that the instructor links to. Note: you don’t have to create an account or log-in. Click “continue as guest” in the upper right hand corner to access the drawing tool. 2.1.4 Resources Borer et al. 2009. Some Simple Guidelines for Effective Data Management. Bulletin of the Ecological Society of America. White et al. 2013. Nine simple ways to make it easier to (re)use your data. Ideas in Ecology and Evolution 6. Software Carpentry SQL tutorial Tidy Data "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
