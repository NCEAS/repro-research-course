[["index.html", "Open Science Synthesis for the Delta Science Program: Week 2 Open Science Synthesis for the Delta Science Program: Week 2 0.1 Schedule", " Open Science Synthesis for the Delta Science Program: Week 2 October 24-29, 2021 Open Science Synthesis for the Delta Science Program: Week 2 This book is for week 2 of 3, one-week facilitated synthesis and training events for Delta researchers that will revolve around scientific computing and scientific software for reproducible science. Week 2 will focus on advanced analysis techniques, and group synthesis work in analysis development of the synthesis developed in Week 1. 0.1 Schedule 0.1.1 Code of Conduct Please note that by participating in an NCEAS activity you agree to abide by our Code of Conduct 0.1.2 Logistics 0.1.2.1 Computing Setup 0.1.2.2 The Power of Open To facilitate a lively and interactive learning environment, we’ll be calling on folks to share their code and to answer various questions posed by the instructor. It’s completely okay to say “Pass” or “I Don’t Know” - this is a supportive learning environment and we will all learn from each other. The instructors will be able to see your code as you go to help you if you get stuck, and the lead instructor may share participants’ code to show a successful example or illustrate a teaching moment. 0.1.3 About this book These written materials are the result of a continuous effort at NCEAS to help researchers make their work more transparent and reproducible. This work began in the early 2000’s, and reflects the expertise and diligence of many, many individuals. The primary authors are listed in the citation below, with additional contributors recognized for their role in developing previous iterations of these or similar materials. This work is licensed under a Creative Commons Attribution 4.0 International License. Citation: Jones, Matthew B., Amber E. Budden, Bryce Mecum, S. Jeanette Clark, Julien Brun, Julie Lowndes, Erin McLean, Jessica S. Guo, David S. LeBauer. 2021. Reproducible Research Techniques for Synthesis. NCEAS Learning Hub. Additional contributors: Ben Bolker, Stephanie Hampton, Samanta Katz, Deanna Pennington, Karthik Ram, Jim Regetz, Tracy Teal, Leah Wasser. "],["session-1-re-introductions-and-setup.html", "1 Session 1: Re-Introductions and Setup 1.1 Datasets of Interest", " 1 Session 1: Re-Introductions and Setup 1.1 Datasets of Interest There is an excel spreadsheet of datasets of interest located in the sharepoint here. The vast majority of these datasets are already available online, in some form, which makes synthesis much easier. There are several other datasets that are not yet published, but will be published by week two of the workshop. This chart shows a summary of the excel spreadsheet, with links to published datasets on the left side, and hover text with more information over each bar. The datasets have been categorized (very loosely) into groups, though many of the fish datasets also contain water quality or plankton data. "],["session-2-git-conflicts.html", "2 Session 2: git conflicts 2.1 Learning Objectives 2.2 Introduction 2.3 Collaborating with a trusted colleague without conflicts 2.4 Merge conflicts 2.5 How to resolve a conflict 2.6 Workflows to avoid merge conflicts 2.7 Collaborating using Git", " 2 Session 2: git conflicts 2.1 Learning Objectives In this lesson, you will learn: How to use Git and GitHub to collaborate with colleagues on code What typically causes conflicts when collaborating Workflows to avoid conflicts How to resolve a conflict 2.2 Introduction Git is a great tool for working on your own, but even better for working with friends and colleagues. Git allows you to work with confidence on your own local copy of files with the confidence that you will be able to successfully synchronize your changes with the changes made by others. The simplest way to collaborate with Git is to use a shared repository on a hosting service such as GitHub, and use this shared repository as the mechanism to move changes from one collaborator to another. While there are other more advanced ways to sync git repositories, this “hub and spoke” model works really well due to its simplicity. In this model, the collaborator will clone a copy of the owner’s repository from GitHub, and the owner will grant them collaborator status, enabling the collaborator to directly pull and push from the owner’s GitHub repository. 2.3 Collaborating with a trusted colleague without conflicts We start by enabling collaboration with a trusted colleague. We will designate the Owner as the person who owns the shared repository, and the Collaborator as the person that they wish to grant the ability to make changes to their reposity. We start by giving that person access to our GitHub repository. Setup We will break you into pairs, so choose one person as the Owner and one as the Collaborator Log into GitHub as the `Owner Navigate to the Owner’s training repository (e.g., training_jones) Then, have the Owner visit their training repository created earlier, and visit the Settings page, and select the Manage access screen, and add the username of your Collaborator in the box. Once the collaborator has been added, they should check their email for an invitation from GitHub, and click on the acceptance link, which will enable them to collaborate on the repository. We will start by having the collaborator make some changes and share those with the Owner without generating any conflicts, In an ideal world, this would be the normal workflow. Here are the typical steps. 2.3.1 Step 1: Collaborator clone To be able to contribute to a repository, the collaborator must clone the repository from the Owner’s github account. To do this, the Collaborator should visit the github page for the Owner’s repository, and then copy the clone URL. In R Studio, the Collaborator will create a new project from version control by pasting this clone URL into the appropriate dialog (see the earlier chapter introducing GitHub). 2.3.2 Step 2: Collaborator Edits With a clone copied locally, the Collaborator can now make changes to the index.Rmd file in the repository, adding a line or statment somewhere noticeable near the top. Save your changes. 2.3.3 Step 3: Collaborator commit and push To sync changes, the collaborator will need to add, commit, and push their changes to the Owner’s repository. But before doing so, its good practice to pull immediately before committing to ensure you have the most recent changes from the owner. So, in R Studio’s Git tab, first click the “Diff” button to open the git window, and then press the green “Pull” down arrow button. This will fetch any recent changes from the origin repository and merge them. Next, add the changed index.Rmd file to be committed by cicking the checkbox next to it, type in a commit message, and click ‘Commit.’ Once that finishes, then the collaborator can immediately click ‘Push’ to send the commits to the Owner’s GitHub repository. 2.3.4 Step 4: Owner pull Now, the owner can open their local working copy of the code in RStudio, and pull those changes down to their local copy. Congrats, the owner now has your changes! 2.3.5 Step 5: Owner edits, commit, and push Next, the owner should do the same. Make changes to a file in the repository, save it, pull to make sure no new changes have been made while editing, and then add, commit, and push the Owner changes to GitHub. 2.3.6 Step 6: Collaborator pull The collaborator can now pull down those owner changes, and all copies are once again fully synced. And you’re off to collaborating. Challenge Now that the instructors have demonstrated this conflict-free process, break into pairs and try the same with your partner. Start by designating one person as the Owner and one as the Collborator, and then repeat the steps described above: Step 0: Setup permissions for your collaborator Step 1: Collaborator clones the Owner repository Step 2: Collaborator Edits the README file Step 3: Collaborator commits and pushes the file to GitHub Step 4: Owner pulls the changes that the Collaborator made Step 5: Owner edits, commits, and pushes some new changes Step 6: Collaborator pulls the owners changes from GitHub 2.4 Merge conflicts So things can go wrong, which usually starts with a merge conflict, due to both collaborators making incompatible changes to a file. While the error messages from merge conflicts can be daunting, getting things back to a normal state can be straightforward once you’ve got an idea where the problem lies. A merge conflict occurs when both the owner and collaborator change the same lines in the same file without first pulling the changes that the other has made. This is most easily avoided by good communication about who is working on various sections of each file, and trying to avoid overlaps. But sometimes it happens, and git is there to warn you about potential problems. And git will not allow you to overwrite one person’s changes to a file with another’s changes to the same file if they were based on the same version. The main problem with merge conflicts is that, when the Owner and Collaborator both make changes to the same line of a file, git doesn’t know whose changes take precedence. You have to tell git whose changes to use for that line. 2.5 How to resolve a conflict Abort, abort, abort… Sometimes you just made a mistake. When you get a merge conflict, the repository is placed in a ‘Merging’ state until you resolve it. There’s a commandline command to abort doing the merge altogether: git merge --abort Of course, after doing that you stull haven’t synced with your collaborator’s changes, so things are still unresolved. But at least your repository is now usable on your local machine. Checkout The simplest way to resolve a conflict, given that you know whose version of the file you want to keep, is to use the commandline git program to tell git to use either your changes (the person doing the merge), or their changes (the other collaborator). keep your collaborators file: git checkout --theirs conflicted_file.Rmd keep your own file: git checkout --ours conflicted_file.Rmd Once you have run that command, then run add, commit, and push the changes as normal. Pull and edit the file But that requires the commandline. If you want to resolve from RStudio, or if you want to pick and choose some of your changes and some of your collaborator’s, then instead you can manually edit and fix the file. When you pulled the file with a conflict, git notices that there is a conflict and modifies the file to show both your own changes and your collaborator’s changes in the file. It also shows the file in the Git tab with an orange U icon, which indicates that the file is Unmerged, and therefore awaiting you help to resolve the conflict. It delimits these blocks with a series of less than and greater than signs, so they are easy to find: To resolve the conficts, simply find all of these blocks, and edit them so that the file looks how you want (either pick your lines, your collaborators lines, some combination, or something altogether new), and save. Be sure you removed the delimiter lines that started with &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt;. Once you have made those changes, you simply add, commit, and push the files to resolve the conflict. 2.5.1 Producing and resolving merge conflicts To illustrate this process, we’re going to carefully create a merge conflict step by step, show how to resolve it, and show how to see the results of the successful merge after it is complete. First, we will walk through the exercise to demonstrate the issues. 2.5.1.1 Owner and collaborator ensure all changes are updated First, start the exercise by ensuring that both the Owner and Collaborator have all of the changes synced to their local copies of the Owner’s repositoriy in RStudio. This includes doing a git pull to ensure that you have all changes local, and make sure that the Git tab in RStudio doesn’t show any changes needing to be committed. 2.5.1.2 Owner makes a change and commits From that clean slate, the Owner first modifies and commits a small change inlcuding their name on a specific line of the README.md file (we will change line 4). Work to only change that one line, and add your username to the line in some form and commit the changes (but DO NOT push). We are now in the situation where the owner has unpushed changes that the collaborator can not yet see. 2.5.1.3 Collaborator makes a change and commits on the same line Now the collaborator also makes changes to the same (line 4) of the README.md file in their RStudio copy of the project, adding their name to the line. They then commit. At this point, both the owner and collaborator have committed changes based on their shared version of the README.md file, but neither has tried to share their changes via GitHub. 2.5.1.4 Collaborator pushes the file to GitHub Sharing starts when the Collaborator pushes their changes to the GitHub repo, which updates GitHub to their version of the file. The owner is now one revision behind, but doesn’t yet know it. 2.5.1.5 Owner pushes their changes and gets an error At this point, the owner tries to push their change to the repository, which triggers an error from GitHub. While the error message is long, it basically tells you everything needed (that the owner’s repository doesn’t reflect the changes on GitHub, and that they need to pull before they can push). 2.5.1.6 Owner pulls from GitHub to get Collaborator changes Doing what the message says, the Owner pulls the changes from GitHub, and gets another, different error message. In this case, it indicates that there is a merge conflict because of the conflicting lines. In the Git pane of RStudio, the file is also flagged with an orange ‘U’, which stands for an unresolved merge conflict. 2.5.1.7 Owner edits the file to resolve the conflict To resolve the conflict, the Owner now needs to edit the file. Again, as indicated above, git has flagged the locations in the file where a conflict occcurred with &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt;. The Owner should edit the file, merging whatever changes are appropriate until the conflicting lines read how they should, and eliminate all of the marker lines with with &lt;&lt;&lt;&lt;&lt;&lt;&lt;, =======, and &gt;&gt;&gt;&gt;&gt;&gt;&gt;. Of course, for scripts and programs, resolving the changes means more than just merging the text – whoever is doing the merging should make sure that the code runs properly and none of the logic of the program has been broken. 2.5.1.8 Owner commits the resolved changes From this point forward, things proceed as normal. The owner first ‘Adds’ the file changes to be made, which changes the orange U to a blue M for modified, and then commits the changes locally. The owner now has a resolved version of the file on their system. 2.5.1.9 Owner pushes the resolved changes to GitHub Have the Owner push the changes, and it should replicate the changes to GitHub without error. 2.5.1.10 Collaborator pulls the resolved changes from GitHub Finally, the Collaborator can pull from GitHub to get the changes the owner made. 2.5.1.11 Both can view commit history When either the Collaborator or the Owner view the history, the conflict, associated branch, and the merged changes are clearly visible in the history. Merge Conflict Challenge Now it’s your turn. In pairs, intentionally create a merge conflict, and then go through the steps needed to resolve the issues and continue developing with the merged files. See the sections above for help with each of these steps: Step 0: Owner and collaborator ensure all changes are updated Step 1: Owner makes a change and commits Step 2: Collaborator makes a change and commits on the same line Step 3: Collaborator pushes the file to GitHub Step 4: Owner pushes their changes and gets an error Step 5: Owner pulls from GitHub to get Collaborator changes Step 6: Owner edits the file to resolve the conflict Step 7: Owner commits the resolved changes Step 8: Owner pushes the resolved changes to GitHub Step 9: Collaborator pulls the resolved changes from GitHub Step 10: Both can view commit history 2.6 Workflows to avoid merge conflicts Some basic rules of thumb can avoid the vast majority of merge conflicts, saving a lot of time and frustration. These are words our teams live by: Communicate often Tell each other what you are working on Pull immediately before you commit or push Commit often in small chunks. A good workflow is encapsulated as follows: Pull -&gt; Edit -&gt; Add -&gt; Pull -&gt; Commit -&gt; Push Always start your working sessions with a pull to get any outstanding changes, then start doing your editing and work. Stage your changes, but before you commit, Pull again to see if any new changes have arrived. If so, they should merge in easily if you are working in different parts of the program. You can then Commit and immediately Push your changes safely. Good luck, and try to not get frustrated. Once you figure out how to handle merge conflicts, they can be avoided or dispatched when they occur, but it does take a bit of practice. 2.7 Collaborating using Git 2.7.1 Learning Objectives In this lesson, you will learn: New mechanisms to collaborate using git What is a Pull Request in Github? How to contribute code to colleague’s repository using Pull Requests What is a branch in git? How to use a branch to organize code What is a tag in git and how is it useful for collaboration? 2.7.2 Pull requests We’ve shown in other chapters how to directly collaborate on a repository with colleagues by granting them write privileges as a collaborator to your repository. This is useful with close collaborators, but also grants them tremendous latitude to change files and analyses, to remove files from the working copy, and to modify all files in the repository. Pull requests represent a mechanism to more judiciously collaborate, one in which a collaborator can suggest changes to a repository, the owner and collaborator can discuss those changes in a structured way, and the owner can then review and accept all or only some of those changes to the repository. This is useful with open source code where a community is contributing to shared analytical software, to students in a lab working on related but not identical projects, and to others who want the capability to review changes as they are submitted. To use pull requests, the general procedure is as follows. The collaborator first creates a fork of the owner’s repository, which is a cloned copy of the original that is linked to the original. This cloned copy is in the collaborator’s GitHub account, which means they have the ability to make changes to it. But they don’t have the right to change the original owner’s copy. So instead, they clone their GitHub copy onto their local machine, which makes the collaborator’s GitHub copy the origin as far as they are concerned. In this scenario, we generally refer to the Collaborator’s repository as the remote origin, and the Owner’s repository as upstream. Pull requests are a mechanism for someone that has a forked copy of a repository to request that the original owner review and pull in their changes. This allows them to collaborate, but keeps the owner in control of exactly what changed. 2.7.3 Exercise: Create and merge pull requests In this exercise, work in pairs. Each pair should create a fork of their partner’s training repository, and then clone that onto their local machine. Then they can make changes to that forked repository, and, from the GitHub interface, create a pull request that the owner can incorporate. We’ll walk through the process from both the owner and the collaborator’s perspectives. In the following example, mbjones will be the repository owner, and metamattj will be the collaborator. Change settings (Owner): Edit the github settings file for your training-test repository, and ensure that the collaborator does not have editing permission. Also, be sure that all changes in your repository are committed and pushed to the origin server. Fork (Collaborator): Visit the GitHub page for the owner’s GitHub repository on which you’d like to make changes, and click the Fork button. This will create a clone of that repository in your own GitHub account. You will be able to make changes to this forked copy of the repository, but you will not be able to make direct changes to the owner’s copy. After you have forked the repository, visit your GitHub page for your forked repository, copy the url, and create a new RStudio project using that repository url. Edit README.md (Collaborator): The collaborator should make one or more changes to the README.md file from their cloned copy of the repository, commit the changes, and push them to their forked copy. At this point, their local repo and github copy both have the changes that they made, but the owner’s repository has not yet been changed. When you now visit your forked copy of the repository on Github, you will now see your change has been made, and it will say that This branch is 1 commit ahead of mbjones:main. Create Pull Request (Collaborator): At this point, click the aptly named Pull Request button to create a pull request which will be used to ask that the owner pull in your changes to their copy. When you click Create pull request, provide a brief summary of the request, and a more detailed message to start a conversation about what you are requesting. It’s helpful to be polite and concise while providing adequate context for your request. This will start a conversation with the owner in which you can discuss your changes, they can easily review the changes, and they can ask for further changes before the accept and pull them in. The owner of the repository is in control and determines if and when the changes are merged. Review pull request (Owner): The owner will get an email notification that the Pull Request was created, and can see the PR listed in their Pull requests tab of their repsoitory. The owner can now initiate a conversation about the change, requesting further changes. The interface indicates whether there are any conflicts with the changes, and if not, gives the owner the option to Merge pull request. Merge pull request (Owner): Once the owner thinks the changes look good, they can click the Merge pull request button to accept the changes and pull them into their repository copy. Edit the message, and then click Confirm merge. Congratulations, the PR request has now been merged into the owner’s copy, and has been closed with a note indicating that the changes have been made. Sync with owner (Collaborator): Now that the pull request has been merged, there is a new merge commit in the Owner’s repository that is not present in either of the collaborator’s repositories. To fix that, one needs to pull changes from the upstream repository into the collaborator’s local repository, and then push those changes from that local repository to the collaborator’s origin repository. To add a reference to the upstream remote (the repository you made your fork from), in the terminal, run: git remote add upstream https://github.com/ORIGINAL_OWNER/ORIGINAL_REPOSITORY.git Then to pull from the main branch of the upstream repository, in the terminal, run: git pull upstream main At this point, the collaborator is fully up to date. 2.7.4 Branches Branches are a mechanism to isolate a set of changes in their own thread, allowing multiple types of work to happen in parallel on a repository at the same time. These are most often used for trying out experimental work, or for managing bug fixes for historical releases of software. Here’s an example graph showing a branch2.1 that has changes in parallel to the main branch of development: The default branch in almost all repositories is called main, and it is the branch that is typically shown in the GitHub interface and elsewhere. There are many mechanisms to create branches. The one we will try is through RStudio, in which we use the branch dialog to create and switch between branches. 2.7.4.1 Exercise: Create a new branch in your training repository called exp-1, and then make changes to the RMarkdown files in the directory. Commit and push those changes to the branch. Now you can switch between branches using the github interface. "],["session-2-collaborative-synthesis.html", "3 Session 2: Collaborative Synthesis", " 3 Session 2: Collaborative Synthesis "],["session-3-introduction-to-bayesian-modeling.html", "4 Session 3: Introduction to Bayesian modeling 4.1 Learning Objectives 4.2 Why choose Bayesian? 4.3 Review of probability, Bayes’ rule, and distributions 4.4 Drafting Bayesian models 4.5 Simple hierachical example: snow fences", " 4 Session 3: Introduction to Bayesian modeling 4.1 Learning Objectives In this lesson, you will learn: Why Bayesian approaches are useful Refresher on probability, distributions, and Bayes’ rule Drafting models with directed acyclic graphs 4.2 Why choose Bayesian? 4.2.1 Philosophically sound and consistent While the methods section of a Bayesian paper can seem complex and opaque, the underlying principles of Bayesian thinking are more intuitive than for frequentist tests. Kruschke (2015) breaks Bayesian data analysis down into two foundational principles: Using data to reallocate credibility among possibilities The possibilities are parameter values in meaningful mathematical models Suppose we step outside and notice that a cultivated plant is yellowing and losing its leaves. We can consider the many possible causes, such as under watering or over watering, among others. Each possibility has some prior credibility based on previous knowledge. For example, where I live in the Sonoran desert, drought or under watering has a greater probability of causing mortality than over watering. As we continue to walk around the garden, we collect new observations. If the other individuals of the same species are green and thriving, we might decrease the probability of under watering, which would probably affect all individuals similarly, and increase the probability of over watering (e.g., leaking pipe). Therefore, Bayesian inference closely mimics deductive reasoning in its reallocation of credibility across possibilities. In real life, data are noisy and inferences are probabilistic. For example, consider testing for COVID in a population where the test is not perfect and can produce both false positive and false negatives. But, we must take into account the prevalence of COVID in population. In areas with high disease prevalence, the false positive rate is lower than in areas with low prevalence. Therefore, the true outcome (positive or negative for COVID) depends on previous knowledge of COVID prevalence and the noisy data (imperfect COVID test). We use Bayesian inference to reallocate credibility across the possibilities. The second foundational principle calls us to define and therefore constrain the set of possibilities. We begin by describing the data from a family of candidate distributions, which are mathematical formulas that can characterize the trends and spreads in data. Each of these distributions is defined by one or more parameter values, which determine the exact shape of the distribution. In Bayesian inference, model parameters are the possibilities over which credibility is allocated. For example, the above histograms show a roughly unimodal and symmetric distribution. The red and blue lines represent candidate descriptions of the data, normal distributions with different sets of parameter values (\\(\\mu, \\sigma\\)). Both choices are plausible, but given the data, the red line has greater credence. Bayesian inference uses the prior probabilities and the data to compute the exact credibility of parameter values. 4.2.2 Flexible Bayesian modeling allows practitioners to design models to fit the data they have, rather than transforming data in an attempt to satisfy model assumptions. This flexibility extends to accounting for hierarchy, treating data as drawn from any kind of distribution, and defining meaningful parameters. For an example of hierarchy, consider a trait collected across multiple individuals and nested within taxonomic levels. We might be interested in comparisons across species, genera, and families. A hierarchical means model might specify: \\(trait_i \\sim Normal(\\mu_{sp(i)}, \\sigma^2)\\) \\(\\mu_{sp} \\sim Normal(\\mu_{g(sp)}, \\sigma^2_{g})\\) \\(\\mu_{g} \\sim Normal(\\mu_{f(g)}, \\sigma^2_{f})\\) where sp represents species, g represents genus, and f represents families. The notation indicates that each observation i belongs to a species, each species belongs to a genus, and each genus belongs to a family. Thus, in a single model, the hierarchical relationship between species, genus, and family can be represented. Data can also be treated as arising from any distribution. For example, a inventory survey might yield counts of a particular species, but those counts might be clumped on the landscape, yielding large number of zero observations. A Poisson distribution describes the probability of a given number of events occurring in an interval of time or space, but doesn’t accommodate the extra zeros. In Bayesian modeling, it is straightforward to specify the surveyed counts as a mixture between Bernoulli and Poisson distributions, which accounts for the separate processes of dispersal (species arrives or not in plot) and frequency (if species arrives, the rate or density of arrival). Finally, Bayesian inference can accommodate a wide range of model and data possibilities, rather than having separate tools or approaches for different types of data or tests. T-test, ANOVA, linear model, non-linear models, and more can be specified in the same framework, using the same set of tools, and can even be combined. This allows the implementation of mathematical models with scientifically meaningful parameters, possibly in conjunction with an ANOVA or regression framework. For example, we might have leaf-level gas exchange data and want to fit a biochemical model of photosynthesis, but the scientific question is whether photosynthetic parameters differed between species and treatments. The flexible nature of a hierarchical approach means that the meaningful parameters (e.g., \\(V_{cmax}\\)) can be represented by a linear model. We can use the data to make inference about the meaningful parameters in one step. 4.2.3 Clear inference In frequentist paradigms, confidence intervals and p-values have very specific, non-intuitive definitions. A 95% confidence interval indicates that out of 100 replications of the experiment, 95% of the resulting confidence intervals will include the true parameter value. In contrast, Bayesian inference results in parameters themselves having distributions, and conditioned on a particular dataset, the 95% credible interval includes 95% of the probability of the parameter value. Bayesian credible intervals and p-values are simple to define, calculate, and interpret. A corollary to the direct quantification of uncertainty is that the purpose of the analysis can be on estimation of parameters, rather than strict hypothesis testing. Bayesian inference provides a way to quantitatively describe relationships in complex datasets, which allows for inquiry to be driven by questions and models of understanding, rather than falsifiable hypotheses. 4.2.4 Uses all available information Bayesian modeling allows for simultaneous analysis of multiple-related datasets. For example, a response variable and its measurement error can be incorporated into a single analysis. Partially missing data do not have to be excluded, and in fact the missing values can be imputed by the model in the same step as the analysis. Finally, prior knowledge can be included in the form of informative priors. In practice, many Bayesian practitioners use relatively non-informative priors, but knowledge of the acceptable values a parameter can take can be incorporated as informative priors, which can improve model speed and convergence. Brainstorming: Possible applications of Bayesian modeling Have you encountered any research roadblocks, past or present, that could potentially be addressed with the techniques mentioned above? 4.3 Review of probability, Bayes’ rule, and distributions 4.3.1 Probabability We define the marginal probability as the total area of circles A and B. \\(P(A) = {A_A}\\) \\(P(B) = {A_B}\\) The joint probability is the shared area of circles A and B. \\(P(A,B) = A_{AB}\\) The conditional probability describes the the shared area scaled by the whole area of one circle. \\(P(B|A) = \\frac{A_{AB}}{A_A}\\) \\(P(B|A) = \\frac{P(A,B)}{P(A)}\\) The joint probability can be rearranged algebraically to produce: \\(P(A,B) = P(B|A)P(A)\\) Thus, we can describe the joint probability as a product of a conditional and marginal probabilities. Interactive problem: Conditional probability Conditional probability rules are very useful for breaking down complex problems. What are some possible ways to break down \\(P(A, B, C)\\)? 4.3.2 Bayes’ rule Bayes’ rule can be derived by describing the joint probability in two ways. \\(P(A,B) = P(B|A)P(A)\\) \\(P(A,B) = P(A|B)P(B)\\) By setting these two descriptions equal to each other and rearranging algebraically, we obtain: \\(P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\\) Thus, we can obtain the conditional probability of \\(A|B\\) from the conditional probability of \\(B|A\\), plus the marginal probabilities of A and B. Interactive problem: Applying Bayes’ rule On a hike, we observe a dead tree and wonder, what is the probability the tree was attacked by beetles, given that it is dead? There are two random variables of interest, beetle and death, each of which can take on the values 1 or 0. We are interested in \\(P(beetle = 1 | death = 1)\\). Recent data show the following probabilities: Condition Probability \\(P(beetle = 0)\\) 0.7 \\(P(beetle = 1)\\) 0.3 \\(P(death = 0|beetle = 0)\\) 0.8 \\(P(death = 0|beetle = 1)\\) 0.1 \\(P(death = 1|beetle = 0)\\) 0.2 \\(P(death = 1|beetle = 1)\\) 0.9 What is \\(P(beetle = 1 | death = 1)\\)? 4.3.3 Bayesian inference In Bayesian inference, we can use the inversion of probability from Bayes’ rule to understand the conditional probability of the parameters given the data from the conditional probability of the data. Here, we use \\(y\\) to represent data and \\(\\theta\\) to represent parameters: \\(P(\\theta|y) = \\frac{P(y|\\theta)P(\\theta)}{P(y)}\\) To simplify further, we can remove the marginal probability of \\(y\\), which is the normalizing constant in the denominator. The unnormalized posterior distribution can be described as: \\(P(\\theta|y) \\propto {P(y|\\theta)P(\\theta)}\\) We read this as ‘the posterior is proportional to the likelihood times the prior’. In Bayesian inference, we can learn about the posterior parameter distribution given the observed data. In so doing, we specify the data as stochastically drawn from a probability distribution conditioned on the ‘true’ parameter values and define the prior probability of those parameters. 4.3.4 Quick review of distributions We identified above that to derive the posterior parameter probabilities, we need to specify both the likelihood and the prior. To do so, we should be aware of a handful of probability distributions that mathematically describe a sample space, or possible outcomes of a random variable. Continuous Description Discrete Description Normal Domain: \\((-\\infty, \\infty)\\)Parameters: \\(\\mu\\) and \\(\\sigma\\)Example: Net ecosystem exchange Poisson Domain: 0 to \\(\\infty\\)Parameter: \\(\\lambda\\)Example: Count data Gamma Domain: \\((0, \\infty)\\)Parameters: \\(\\alpha\\) and \\(\\beta\\)Example: Rates Bernoulli Domain: 0 or 1Parameter: \\(p\\)Example: Presence or absence Beta Domain: \\((0, 1)\\)Parameters: \\(\\alpha\\) and \\(\\beta\\)Example: Survival probability Binomial Domain: 0 to \\(\\infty\\)Parameters: \\(n, p\\)Example: Deaths in a population Once we are aware of the general features of distributions, we can select an appropriate likelihood for the data. The likelihood should match the data and the data-generating process. A few questions to consider are: Are the data (response variables) continuous or discrete? What are the range of possible values that the data can take? How does the variance of the data change as a function of the mean? Interactive problem: Identifying potential likelihoods For each example, identify the potential probability distribution(s) that would be appropriate. Use the questions above to guide your choices. Number of trees classified as dead in a forest plot Total leaf area of a tree Reproductive status of an individual (reproductive vs. non-reproductive) Proportion of trees classified as dead in a forest plot Seed mass Number of sea stars in a tide pool Concentration of oxygen in seawater Time between flood events 4.3.5 Selecting priors Selecting a likelihood to describe the data distribution is necessary but not sufficient for specifying a Bayesian model. Careful thought must be put in to picking priors as well, which represent existing knowledge about a parameter. A few questions to consider are: What range can the parameter take mathematically? What values are ecologically realistic? Is there an appropriate conjugate prior for this likelihood? Conjugacy has a formal definition, but for our purposes, natural conjugate prior families have practical advantages for computation and interpretation. Some examples include the binomial-beta, Poisson-gamma, multinomial-Dirichlet, and exponential-gamma. For a normal likelihood, the conjugate prior for \\(\\mu\\) is normal and the conjugate prior for \\(\\sigma^2\\) is the inverse-gamma. In common Bayesian simulation software such as JAGS, OpenBUGS, and Stan, the scale parameter of a normal likelihood is defined as the precision (\\(\\tau = \\frac{1}{\\sigma^2}\\)); the conjugate prior for \\(\\tau\\) is a gamma distribution. Selecting priors is an important consideration of Bayesian modeling that will have its own lecture later in the week. For now, we can say that many parameters do not need informative priors in order to be reliably estimated by the data (e.g., regression parameters). Other parameters, such as observation error, will rarely be identifiable without strong prior information (or additional data). In practice, selecting priors can be part of the model development process. Different priors can be tested for their contribution to the posterior, which allows for evaluation of the sensitivity of the posterior to the prior specification. Particularly for non-identifiable parameters, convergence can be achieved more quickly with a more informative prior. One method can be to specify a uniform prior with realistic but conservative upper and lower bounds: \\(\\theta \\sim Uniform(A, B)\\) As such, the posterior distribution for \\(\\theta\\) will also be restricted to the interval [A,B], and the data likelihood will contribute to its shape. 4.4 Drafting Bayesian models Given the flexibility of Bayesian modeling and the considerations of selecting likelihoods and priors, a key step in model development is to write out the model components after considering the features of the scientific question and dataset at hand. The model can be be represented a series of equations, as a diagram, and in code. Ultimately, the manuscript will require the equations in the Methods section and the code as part of the publishing requirement. Diagrams are useful tool to visually represent the model and consider alternative model formulations. 4.4.1 Graphical representations of hierarchical models Complex or hierarchical models can be easily represented as a graphical model, particularly a Directed Acyclic Graph (DAG). General convention for DAGs in Bayesian modeling are: Nodes can be stochastic (circles) or deterministic/fixed (squares) Child nodes depend on parent nodes A root node does not have any parents A terminal node does not have any children An internal node gives rise to children nodes and has parent node(s) Edges are directional (arrows) that indicate the direction of the conditional relationship between two nodes Edges must be unidirectional (node A cannot be parent to and child of node B) No sequence of edges returns to the parent node In this DAG, A is a root node, C is a terminal node, and B is an internal node. The conditional probability model can be defined as: \\(P(A, B, C) = P(C|B)P(B|A)P(A)\\) We will see in the example below that DAGs can be especially useful for visualizing the mathematical representation of models. 4.5 Simple hierachical example: snow fences Consider a study to quantify the effects of snow fences on invasive plant establishment. 10 snow fences are monitored and their invasive plants counted within the “footprint” of each snow fence. Let \\(y_i\\) represent the number of invasive plants associated with snow fence \\(i\\). Let \\(x_i\\) represent the footprint (in square meters) of snow fence \\(i\\) The data are: \\(i\\) \\(y_i\\) \\(x_i\\) 1 138 72 2 91 50 3 132 55 4 123 60 5 173 78 6 124 63 7 109 54 8 154 70 9 138 80 10 134 68 Given these count data, let’s define the likelihood with a Poisson distribution. However, we have reason to believe that each snow fence has its own rate of invasive plants due to local topographical factors. Therefore, we specify the likelihood as: \\(y_i \\sim Poisson(\\theta_i \\cdot x_i)\\) such that each snow fence \\(i\\) has its own rate parameter, \\(\\theta_i\\). However, given that the snow fences are located at the same field site, we believe that the individual rates of invasive plants are drawn from an overall regional rate: \\(\\theta_i \\sim Gamma(\\alpha, \\beta)\\) In this hierarchical model, the prior for the parameter of interest is a gamma distribution described by \\(\\alpha\\) and \\(\\beta\\), which are unknown/stochastic. So, we must define these hyperparameters with their own priors. \\(\\alpha \\sim Gamma(2, 1)\\) \\(\\beta \\sim Exponential(1)\\) The hyperparameters \\(\\alpha\\) and \\(\\beta\\) are root nodes, whose distributions are fixed rather than stochastic. The levels of this hierarchical model can be visualized by the following DAG: The bolded variables indicate vectors, which are indexed by \\(i\\) in statistical notation. The rectangle around \\(\\bf{x}\\) indicates that it is a deterministic node, or fixed as data. Notably,the oval around the response variable \\(\\bf{y}\\) indicates that it is a stochastic node; that is, drawn from a distribution and given the Poisson likelihood. \\(\\bf{\\theta}\\) is the parameter in the Poisson likelihood, and it is drawn from a conjugate gamma prior with two parameters, \\(\\alpha\\) and \\(\\beta\\). All of the stochastic nodes (ovals) are drawn from distributions. \\(\\alpha\\) and \\(\\beta\\) are root nodes, meaning that the parameter values for their distributions are fixed and must be defined numerically. Interactive problem: Logistic regression example Consider the case of selection pressure from discoloring of tree trunks from air pollution. One species of moth rests on tree trunks during the day, and their coloration acts as camouflage against bird predation. Researchers established a gradient of tree trunk color from Liverpool the countryside and selected 7 sites. At each site, they glued an equal number of dead light and dead dark moths to tree trunks and counted the number of removed moths after 24 hours. The dataset includes Site (1,2, … 7), Morph (1 = light, 2 = dark), Distance (from Liverpool, km) Placed (number of moths glued to trunks), and Removed (number of moths removed from trunks after 24 hours). \\(Site\\) \\(Morph\\) \\(Distance\\) \\(Placed\\) \\(Removed\\) 1 1 0 56 17 1 2 0 56 14 2 1 7.2 80 28 2 2 7.2 80 20 3 1 24.1 52 18 3 2 24.1 52 22 4 1 30.2 60 9 4 2 30.2 60 16 5 1 36.4 60 16 5 2 36.4 60 23 6 1 41.5 84 20 6 2 41.5 84 40 7 1 51.2 92 24 7 2 51.2 92 39 Here, our goal is to evaluate whether the probability of removal differed between the light and dark morphs, and whether this difference depends on distance from Liverpool. Consider the following: Let \\(y\\) represent the number of removed moths and \\(n\\) represent the number of moths placed. Write out the likelihood for this response variable. The probability \\(p\\) of removal differs depending on distance from Liverpool, \\(x\\). Thus, we should index the variables as \\(p_i\\) and \\(x_i\\), to indicate that each observation will be associated with a unique probability. Let \\(\\beta_1\\) and \\(\\beta_2\\) as the intercept and slope of a linear regression. Write out the expression relating \\(p_i\\) as linear function of \\(x_i\\). Furthermore, we hypothesize that color morph influences the relationship with distance. Let \\(\\beta_1\\) and \\(\\beta_2\\) each be vectors. How can the linear function be updated to account for the morph of observation \\(i\\)? Regressions work best on the whole real line, but probability \\(p\\) can only take on values between \\([0,1]\\). What kind of link function can be used to relate \\([0,1]\\) to the whole real line? Priors are needed for the regression parameters. In the absence of prior information, what might be a relatively non-informative prior to give \\(\\beta_1\\) and \\(\\beta_2\\)? Draw a DAG for this model. 4.5.1 Acknowledgements These materials are derived primarily from Bayesian course materials developed and taught by Kiona Ogle. Additional ideas and code have been adapted from materials authored by Kelly Heilman, Robert Shriver, and Drew Peltier. The texts ‘Doing Bayesian Data Analyis’ (Kruschke 2015), ‘Statistical Rethinking’ (McElreath 2016), and ‘Bayesian Data Analysis’ (Gelman et al. 2014) were strongly influential and recommended references. "],["session-4-collaborative-synthesis.html", "5 Session 4: Collaborative Synthesis", " 5 Session 4: Collaborative Synthesis "],["session-5-implementing-bayesian-models.html", "6 Session 5: Implementing Bayesian models 6.1 Learning Objectives 6.2 Overview of the Bayesian modeling process 6.3 Markov chain Monte Carlo 6.4 Programing statistical models 6.5 Evaluating model diagnostics", " 6 Session 5: Implementing Bayesian models 6.1 Learning Objectives In this lesson, you will learn: Overview of the Bayesian modeling process Introduction to MCMC Programming model in software Evaluating model diagnostics 6.2 Overview of the Bayesian modeling process In the first part of the lecture, we established the major reasons to use Bayesian inference and briefly reviewed the fundamentals of probability, Bayes’ rule, and distributions. We ended by walking through two examples that allowed us to practice model specification. In this lesson, we will explain and demonstrate how to ‘translate’ between statistical notation and model code, with particular emphasis on implementing Bayesian models with MCMC software. 6.3 Markov chain Monte Carlo MCMC is a general method where samples are drawn sequentially from a proposal distribution that depends on the last value in the sequence. These draws form a Markov chain because the probability of accepting a proposed value of \\(\\theta\\) in iteration \\(j\\) depends on the value of \\(\\theta\\) in iteration \\(j-1\\). Each iteration improves the proposal distribution until it eventually approximates (converges upon) the posterior distribution. Two popular MCMC algorithms are the Metropolis-Hastings algorithm and the Gibbs sampler. Both procedures are highly random, although Gibbs sampling is more efficient at proposing values by reducing this randomness. The software OpenBUGS and JAGS both utilize Gibbs sampling and can interface with R using packages such as ‘rjags’ and ‘R2OpenBUGS’. Hamiltonian Monte Carlo (HMC) and its variant No-U-Turn sampler are much more computationally intensive, but more efficient algorithms that are available in the imperative programming language Stan. Popular R interface packages include ‘rstan’, ‘rethinking’, and ‘brms’. Chapter 8 of McElreath’s ‘Statistical Rethinking’ (2016) provides a great overview of MCMC algorithms at the level suitable for applied practitioners, while greater detail of the algorithms can be found in chapters 11-12 of ‘Bayesian Data Analysis’ (Gelman et al. 2014). 6.3.1 Inference from iterative simulation Using MCMC simulation software frees us from having to compute the posterior analytically, but adds the following considerations: The simulation must be run long enough such that the distribution of \\(\\theta\\) closely approximates the true posterior distribution Iterative simulation can result in within-sequence correlation, such that inference can be less precise than with independent draws To address these issues, simulation can be run for multiple sequences and initiated at dispersed starting points within the parameter space. It is highly recommended that at least 3 chains are run. If the runs are initiated with dispersed starting values, yet ultimately describe the same posterior, we say that the model has converged. One rule of thumb is to aim for 3000-4000 ‘independent’ posterior samples. Since each MCMC sample depends on the previous proposal, the samples are not truly independent. In practice, trial runs of the model can be used to assess autocorrelation within chains. We can then set the number of iterations and the thinning interval to obtain the desired number of ‘independent’ posterior samples. Below, we’ll use an example below to illustrate how to specify starting values, determine chain length, and perform posterior predictive checks. 6.4 Programing statistical models Let’s revisit the snow fence example from the previous lecture. We have already described the model both mathematically and with a DAG. Next, we need to implement the set of equations in an MCMC software. In this lesson, we will use JAGS interfaced from R with the package ‘rjags’. JAGS shares some syntax with R, but is not declarative and not vectorized. In practice, this means that the order of statements does not matter, and that operations that apply to a vector of values must be contained within a for loop. To start a model, write a for loop for the number of observations (N) in the dataset. Then, specify the likelihood within that data loop. \\(y_i \\sim Poisson(\\theta_i \\cdot x_i)\\) &quot;model{ for(i in 1:N){ y[i] ~ dpois(theta[i]*x[i]) } }&quot; Note that the subscript indexing from the mathematical notation is retained as indices within square brackets. Next, consider the probability distribution of \\(\\theta_i\\). \\(\\theta_i \\sim Gamma(\\alpha, \\beta)\\) &quot;model{ for(i in 1:N){ y[i] ~ dpois(theta[i]*x[i]) theta[i] ~ dgamma(alpha, beta) } }&quot; The distribution for \\(\\theta_i\\) also occurs within the data loop, because our model specifies that each observation has its own rate of invasive plants, drawn from a gamma distribution. We provide priors for the hyperparameters \\(\\alpha\\) and \\(\\beta\\). \\(\\alpha \\sim Gamma(2, 1)\\) \\(\\beta \\sim Exponential(1)\\) &quot;model{ for(i in 1:N){ y[i] ~ dpois(theta[i]*x[i]) theta[i] ~ dgamma(alpha, beta) } alpha ~ dgamma(2, 1) beta ~ dexp(1) }&quot; These hyperparameters are scalars that must be defined outside of the data loop. As root nodes, their parameters are numerical values. Finally, let’s calculate the mean and standard deviation of the population-level invasive plant rate. We know that the mean of a gamma distribution is \\(\\frac{\\alpha}{\\beta}\\), and the variance is \\(\\frac{\\alpha}{\\beta^2}\\). &quot;model{ for(i in 1:N){ y[i] ~ dpois(theta[i]*x[i]) theta[i] ~ dgamma(alpha, beta) } alpha ~ dgamma(2, 1) beta ~ dexp(1) pmean_theta &lt;- alpha/beta pstd_theta &lt;- sqrt(alpha/beta^2) }&quot; 6.4.1 Compiling a JAGS model Fitting a JAGS model consists of two steps. The first step is to compile the model object with jags.model(). This function requires requires the model code, the list of input data, the starting values, and the number of chains. There is also an optional adaption phase, which has a default of 1000 iterations. This is equivalent to discarding the first 1000 sampes as a ‘burn-in’, during which the samplers are adapting behavior to maximize efficiency. Model code I typically recommend that model code be saved as a separate model file, which allows for different versions to be tested without cluttering up the main script. But for simple cases, we can specify the model as a character string and later use textConnection() to read in the model. mstring &lt;- &quot; model{ for(i in 1:N){ y[i] ~ dpois(theta[i]*x[i]) theta[i] ~ dgamma(alpha, beta) } alpha ~ dgamma(2, 1) beta ~ dexp(1) pmean_theta &lt;- alpha/beta pstd_theta &lt;- sqrt(alpha/beta^2) } &quot; List of input data To fit the model we have specified, we will need to provide data for the variables y (number of invasive plants), x (footprint area of snow fence), and N (number of observations). These data must be provided as a list, with list element names that correspond to the variable names used in the model code. sf &lt;- data.frame(y = c(138, 91, 132, 123, 173, 124, 109, 154, 138, 134), x = c(72, 50, 55, 60, 78, 63, 54, 70, 80, 68)) datlist &lt;- list(y = sf$y, x = sf$x, N = nrow(sf)) Initial values Next, we need to consider appropriate and dispersed starting values. Initial values are only needed for root nodes, in this case for \\(\\alpha\\) and \\(\\beta\\). For simple models, we can skip this input and random starting values will be generated from the prior distribution. In more complex cases, we might want to specify realistic but dispersed starting values to speed the time to convergence. Initial values must be appropriate for the domain of the prior. For example, since \\(\\alpha\\) has a exponential distribution, the model will error if the starting value for \\(\\alpha\\) is negative. The function jags.model() requires initial values as a list of lists; the length of the list must correspond to the number of chains specified. Since we desire 3 independent chains, our list of initials will contain 3 lists, each with two elements (alpha and beta). Again, list element names that correspond to the variable names used in the model code. Crude estimates of parameter values are a good starting point for specifying initial values. In this case, we will compute the sample mean for the rate of invasive plant occurrence. mean(sf$y/sf$x) ## [1] 2.028698 On average, there are about 2 invasive plants per square meter across all snow fences. The rate parameter is specified as a gamma distribution, and the mean of a gamma distribution is \\(\\alpha/\\beta\\). We will specify starting values for alpha and beta equivalent to 0.5, 2, and 20. initslist &lt;- list(list(alpha = 0.5, beta = 1), list(alpha = 4, beta = 2), list(alpha = 30, beta = 1.5)) Finally, we can compile the model. jm &lt;- jags.model(file = textConnection(mstring), data = datlist, inits = initslist, n.chains = 3) 6.4.2 Sampling the posterior distribution After the model object has compiled, we will monitor the posterior samples using coda.samples(). This function requires a jags model object, names of variables to monitor, and the number of iterations to monitor. There is also an optional thinning argument, which is set to 1 by default. Thinning can be used to save every \\(i\\)th element of the posterior chain, which can produce more ‘independent’ samples when chains are autocorrelated. jm_coda &lt;- coda.samples(model = jm, variable.names = c(&quot;theta&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;pmean_theta&quot;, &quot;pstd_theta&quot;), n.iter = 3000) 3000 iterations for each of 3 chains ran quickly in our example. 6.5 Evaluating model diagnostics Hooray! The model ran! But before we can summarize the posterior and move on making inferences, we must examine a series of model diagnostics and re-run the model if necessary. There are at least two goals of evaluating the posterior samples: whether chain length was sufficient whether the chains converged If either the number of ‘independent’ samples or convergence among chains falls short, we will have to re-run the model before making inferences. Visual assessment First thing to check are the traceplots, from which we can roughly assess convergence and autocorrelation simultaneously. Here, we use the traplot() function from the package mcmcplots, which allows us to specify which parameter to visualize. traplot(jm_coda, parms = c(&quot;theta&quot;, &quot;alpha&quot;, &quot;beta&quot;)) The traceplots for the theta parameters are textbook ‘fuzzy catepillars’; the values are stable over time, while the three chains are very well-mixed. We can consider the theta parameters converged and of sufficient run length. The alpha and beta parameters are also converged, in that the 3 chains are well-mixed and stable. However, there is some autocorrelation present. We will switch to using the function mcmcplot, which provides the traceplot, autoccorelation, and density for specified parameters as an html file that can be viewed in a web browser. mcmcplot(jm_coda, parms = c(&quot;alpha&quot;, &quot;beta&quot;)) In the autocorrelation plot, the correlation coefficient between the parameter value at iteration \\(t\\) and its value at iteration \\(t-l\\) are visualized, where \\(l\\) represents the lag or offset between iterations. A correlation coefficient near 1 indicates that samples are highly autocorrelated, whereas correlation coefficients near 0 indicate approximately independent samples. For alpha and beta, we see that autocorrelation is high until about 20, indicating that thinning by 20 might be appropriate. Rerunning the model We can re-run the model now and set thinning to 20. But if we are only saving every 20th posterior sample, we should inflate the number of iterations by a factor of 20 to keep the same number of samples. jm &lt;- jags.model(file = textConnection(mstring), data = datlist, inits = initslist, n.chains = 3) jm_coda &lt;- coda.samples(model = jm, variable.names = c(&quot;theta&quot;, &quot;alpha&quot;, &quot;beta&quot;, &quot;pmean_theta&quot;, &quot;pstd_theta&quot;), n.iter = 3000*20, thin = 20) mcmcplot(jm_coda, parms = c(&quot;alpha&quot;, &quot;beta&quot;)) Notice that the model took appreciably longer to run this time, as we have specified that the MCMC be run for 20 times the previous number of iterations. However, we now have posterior samples for alpha and beta that are relatively independent. Numerical confirmation of convergence To quantify convergence, we can use the potential scale reduction factor or \\(\\hat{R}\\), which compares within-chain to between-chain variance for each parameter. In the ‘coda’ package (which is automatically loaded with ‘rjags’), the function for calculating \\(\\hat{R}\\) is gelman.diag(). gelman.diag(jm_coda, multivariate = FALSE) ## Potential scale reduction factors: ## ## Point est. Upper C.I. ## alpha 1 1 ## beta 1 1 ## pmean_theta 1 1 ## pstd_theta 1 1 ## theta[1] 1 1 ## theta[2] 1 1 ## theta[3] 1 1 ## theta[4] 1 1 ## theta[5] 1 1 ## theta[6] 1 1 ## theta[7] 1 1 ## theta[8] 1 1 ## theta[9] 1 1 ## theta[10] 1 1 \\(\\hat{R} \\leq 1.2\\) is generally indicates convergence. Here, all of the parameters have converged, which confirms our visual assessment of convergence. Plotting model output We can visualize the posterior distributions of invasive plant rates with the function caterplot(). caterplot(jm_coda, parms = &quot;theta&quot;, reorder = FALSE) We can see that the rates for each snow fence (\\(\\theta_i\\)) are indeed distributed about the sample mean of 2 invasive plants per square meter. How do the fence-level rates compare with the regional-level rates? We can use the summary() function on the model output samples. summary(jm_coda)[[1]] ## Mean SD Naive SE Time-series SE ## alpha 4.932648 1.7485225 0.018431046 0.020840124 ## beta 2.357358 0.8829682 0.009307302 0.010128396 ## pmean_theta 2.134685 0.3307012 0.003485897 0.003539697 ## pstd_theta 1.008835 0.2539192 0.002676543 0.002781655 ## theta[1] 1.921838 0.1593706 0.001679914 0.001679780 ## theta[2] 1.827899 0.1878863 0.001980496 0.001980480 ## theta[3] 2.391543 0.2051390 0.002162355 0.002162563 ## theta[4] 2.054517 0.1811255 0.001909231 0.001909116 ## theta[5] 2.213020 0.1667914 0.001758135 0.001760979 ## theta[6] 1.971297 0.1704775 0.001796991 0.001781030 ## theta[7] 2.021405 0.1900816 0.002003636 0.002003700 ## theta[8] 2.195808 0.1763917 0.001859332 0.001802335 ## theta[9] 1.735631 0.1466727 0.001546066 0.001544247 ## theta[10] 1.972669 0.1674529 0.001765108 0.001766131 The regional rate of invasive plants has a posterior mean of ~2.4 and a posterior standard deviation of ~1. Thus, this hierarchical model acts as something of a random effects model, allowing us to account for variation among individual snow fences while reporting statistics at the regional level. The distinction between fixed and random effect is blurred in hierarchical Bayesian modeling, and there can be multiple ways of specifying random effects. Interactive problem: Logistic regression model Using the steps described above, work in small groups to code, run, and diagnose the logistic regression model for moth coloration. moths &lt;- data.frame(site = rep(1:7, each = 2), morph = rep(1:2, times = 7), distance = rep(c(0, 7.2, 24.1, 30.2, 36.4, 41.5, 51.2), each = 2), placed = rep(c(56, 80, 52, 60, 60, 84, 92), each = 2), removed = c(13, 14, 28, 20, 18, 22, 9, 16, 16, 23, 20, 40, 24, 39)) Helpful hints: Use the JAGS manual to find the parameters of dbin, the binomial distribution No need to specify initials for this regression model Can add replicated data to evaluate model fit. Create a new variable y.rep beneath the likelihood and give it an identical distribution. Once the model has converged, plot and summarize posterior parameters of interest to address the following questions: Does the probability of predation vary with distance fom Liverpool? Does the probability of predation differ between morphs? Does the effect of distance on predation differ between morphs? How might we evaluate model fit? 6.5.1 Acknowledgements These materials are derived primarily from Bayesian course materials developed and taught by Kiona Ogle. Additional ideas and code have been adapted from materials authored by Kelly Heilman, Robert Shriver, and Drew Peltier. The texts ‘Doing Bayesian Data Analyis’ (Kruschke 2015), ‘Statistical Rethinking’ (McElreath 2016), and ‘Bayesian Data Analysis’ (Gelman et al. 2014) were strongly influential and recommended references. "],["session-6-collaborative-synthesis.html", "7 Session 6: Collaborative Synthesis", " 7 Session 6: Collaborative Synthesis "],["session-7-collaborative-synthesis.html", "8 Session 7: Collaborative Synthesis", " 8 Session 7: Collaborative Synthesis "],["session-8-informative-priors.html", "9 Session 8: Informative Priors 9.1 Priors", " 9 Session 8: Informative Priors 9.1 Priors 9.1.1 Learning Objectives In this lesson you will learn: - Why and when to use informative priors, and how they can be helpful - How to elicit priors from yourself or other experts - How to specify priors from limited data - How to evaluate the sensitivity of your results to priors 9.1.2 Background What are priors? Even outside of Bayesian statistics, the concept of priors is a core component of the scientific process - building on existing knowledge. Further, the use of informative priors is a way of getting the most out of your statistical analysis. \\[ \\overbrace{P(\\theta \\mid X)}^{posterior} \\propto \\overbrace{P(X\\mid \\theta)}^{likelihood}\\,\\overbrace{P(\\theta)}^{prior} \\] 9.1.3 Conjugate Priors Probability distributions have useful relationships. For simple models, Bayes’ Theorem can be solved mathematically. This is very appealing when it applies. The figure below shows some relationships among probability distributions are related. It comes from an interactive website created by John Cook, which brings the paper “A compendium of conjugate priors” by Daniel Fink to life. Digging into the math is mostly beyond the scope of this lesson, except for the following illustrative example. This example is provided to show how the prior, the sample size, and the variance of data influence the posterior estimate. Consider the solution to the ‘normal-normal’ conjugate prior and likelihood. If the prior mean is \\(\\mu_0\\) and the prior variance is \\(\\sigma_0^2\\) And the likelihood mean \\(\\bar{x}\\) and variance \\(s^2\\): Then the posterior mean is \\[ \\frac{1}{\\frac{1}{\\sigma_0^2}+\\frac{n}{\\sigma^2}} \\left( \\frac{\\mu_0}{\\sigma_0^2}+ \\frac{\\sum_{i=1}^{n}{x_i}}{\\sigma^2}\\right) \\] And the posterior variance is: \\[ \\left( \\frac{1}{\\sigma_0^2} +\\frac{n}{\\sigma^2} \\right)^{-1} \\] Questions: Is that math there just to scare you? (hint: no) What happens when the prior variance, \\(\\sigma^2_0\\) , is very large? What happens when the sample size, \\(n\\), is very large? Yes, that is correct. When the sample size and/or the prior variance is large, the influence of the prior diminishes to 0. See also https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading15a.pdf and https://en.wikipedia.org/wiki/Conjugate_prior 9.1.4 Uniformative / Weak / Flat Priors It is common to use what is known as a ‘noninformative’ or ‘flat’ prior. This is often the easiest approach, and is roughly defined by the fact that the priors have no influence on the model. Some common non-informative priors include a standard normal with large variance, such as \\(N(0, 10^4)\\) or a wide uniform distribution - such as \\(U(-10^4, 10^4)\\). Discussion: If you were setting a prior on the size of a fish, what would your prior be? That was a trick question - is size measured as mass or length? Hint: Consider a spherical fish with radius 1cm and density of 1g/ml. Recall \\(V=\\frac{4}{3}\\pi r^3\\) When are informative priors useful? length &lt;- runif(100000, -10000, 10000) mass &lt;- 4/3 * pi * (length / 2) ^ 3 par(mfrow=c(1,2)) hist(length, probability = TRUE, breaks = 100) hist(mass, probability = TRUE, breaks = 100) Correct, even a non-informative prior or ‘flat’ prior on length is not so flat on a different scale. Consider other transformations. What else do you notice about the range of values? Correct, most of the measurements that we make are greater than zero. At a minimum, it is useful to have a prior with a lower bound at zero. These include the log-Normal, Gamma, Weibull, and many other distributions. But as soon as you specify a prior distribution, you are imposing your understanding on the model. This is okay! This is The Way! In conclusion, there really is no such thing as a non-informative prior. However, it is often vastly easier to specify a weak prior than to go through the trouble of justifying an informative prior. 9.1.5 Regularizing priors Regularization priors are relatively non-informative, but on a similar scale as the data. These provide a way to assign 0 probability to impossible values (e.g. a boundary at zero) and to down weight extreme outlines. 9.1.6 Informative Priors Informative priors are particularly useful in contexts with limited available data. In many cases, it will be possible for an expert to use what is already known about a variable to specify a more informative prior. In the ideal case, a posterior from a previous study can be used as the prior for the subsequent study. This is the first step toward iterative forecasting - updating a prediction as new information becomes available. In practice, however, it is often wise to inflate the variance to account for differences across systems - the specific study system (Delta) and what is generally known about freshwater systems. There are many sources of information from which you can specify priors, including: Expert knowledge, including biophysical constraints, logical bounds, or reasonable values based on experience (what are the upper and lower bounds for the length of a mouse?) Lots of data from prior studies on the same system. A little bit of data. A lot or a little bit of data, but from a related system Posterior from a related model, or from the same model at a prior time-step. Prior sensitivity It is prudent to test the sensitivity of your model to your prior assumptions. Having a model that is sensitive to priors is OK, especially when there is a strong rationale and support from data. However, it is necessary to understand how the use of an informative prior affects your posterior estimates. It is very common when using strong priors to find that the MCMC chains do not converge, because the posteriors exist where the priors have very low probaility. This often leads you to uncover differences between how you and the computer understand your model (what you think the code says and what it actually says); it can also point to errors in the data (often related to scale, or unexpected factors that differ), and other assumptions. If applicable, you can plot the data against the prior on Y. Plot the data against The easiest way to do this is to plot the prior PDFs and posterior histograms, and to compare the prior and posterior variances of each parameter. If the ratio of posterior:prior SD &gt; 0.1, you have an informative prior and you should be careful. Think of this in the same way that you think of model specification. You can compare model posteriors fit with different priors in the same way that you can compare models with different structures or parameters, both visually and statistically. 9.1.7 Generating Priors based or Expert knowledge: Package rriskDistributions The rriskDistributions is useful for estimating priors. Individual functions for each distribution such as get.&lt;somedist&gt;.par include diagnostic plots that compare chosen points to cdf. As an example, compute the parameters of a Gamma distribution that fits a median of 2.5 and has a 95%CI of [1, 10]: library(rriskDistributions) get.gamma.par(p = c(0.025, 0.50, 0.975), q = c(1, 2.5, 10), tol = 0.1) ## The fitting procedure &#39;L-BFGS-B&#39; was successful! ## $par ## [1] 6.300745 2.388508 ## ## $value ## [1] 6.942286e-05 ## ## $counts ## function gradient ## 26 26 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; ## shape rate ## 6.300745 2.388508 The function fit.pecr provides a GUI to explore the fits of a range of distributions, e.g.: fit.perc(p = c(0.1, 0.5, 0.9), q = c(30, 60, 90), tolConv = 0.1) Web based elicitation tool http://optics.eee.nottingham.ac.uk/match/uncertainty.php# (Morris et al 2013) Activity: Create your own priors Work with a partner in your project group Choose a parameter in one of the models that you are developing (e.g. growth rate of a fish population, lag between flooding event and peak phytoplankton concentration); Write down what you know about this based on your experience. Start with plausible ranges (max, min) then location of tails - 95% CI. Estimate most likely values and central tendencies (median, mode) last. Choose one of the tools above and generate a set of flat, weak / regularizing, and a strong prior. 9.1.8 Statistical fitting to data More formal, data driven examples are provided in LeBauer et al 2013. Not always worth the trouble. Some code in https://github.com/PecanProject/pecan/blob/develop/modules/priors/vignettes/priors_demo.Rmd Maximum likelihood fitting of parametric distributions to related data Bayesian ‘posterior prediction’ of an unobserved class for which data has been collected from other classes. model{ for (k in 1:length(Y)){ Y[k] ~ dnorm(beta.ft[ft[k]], tau.y[k])T(0,) tau.y[k] &lt;- prec.y*n[k] u1[k] &lt;- n[k]/2 u2[k] &lt;- n[k]/(2*prec.y) obs.prec[k] ~ dgamma(u1[k], u2[k]) } for (f in 1:5){ beta.ft[f] ~ dnorm(0, tau.ft) } tau.ft ~ dgamma(0.1, 0.1) prec.y ~ dgamma(0.1, 0.1) sd.y &lt;- 1 / sqrt(prec.y) ## estimating posterior predictive for new C4 species pi.pavi &lt;- Y[length(Y)] diff &lt;- beta.ft[1] - beta.ft[2] } 9.1.9 References and further reading David E. Morris, Jeremy E. Oakley, John A. Crowe, A web-based tool for eliciting probability distributions from experts, Environmental Modelling &amp; Software, Volume 52, February 2014, Pages 1-4, ISSN 1364-8152, http://dx.doi.org/10.1016/j.envsoft.2013.10.010. Gelman, Lawrence, et al “Prior choice recommendations” Stan Community Wiki https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations "],["session-10-informative-priors.html", "10 Session 10: Informative Priors 10.1 Priors", " 10 Session 10: Informative Priors 10.1 Priors 10.1.1 Learning Objectives In this lesson you will learn: - Why and when to use informative priors, and how they can be helpful - How to elicit priors from yourself or other experts - How to specify priors from limited data - How to evaluate the sensitivity of your results to priors 10.1.2 Background What are priors? Even outside of Bayesian statistics, the concept of priors is a core component of the scientific process - building on existing knowledge. Further, the use of informative priors is a way of getting the most out of your statistical analysis. \\[ \\overbrace{P(\\theta \\mid X)}^{posterior} \\propto \\overbrace{P(X\\mid \\theta)}^{likelihood}\\,\\overbrace{P(\\theta)}^{prior} \\] 10.1.3 Conjugate Priors Probability distributions have useful relationships. For simple models, Bayes’ Theorem can be solved mathematically. This is very appealing when it applies. The figure below shows some relationships among probability distributions are related. It comes from an interactive website created by John Cook, which brings the paper “A compendium of conjugate priors” by Daniel Fink to life. Digging into the math is mostly beyond the scope of this lesson, except for the following illustrative example. This example is provided to show how the prior, the sample size, and the variance of data influence the posterior estimate. Consider the solution to the ‘normal-normal’ conjugate prior and likelihood. If the prior mean is \\(\\mu_0\\) and the prior variance is \\(\\sigma_0^2\\) And the likelihood mean \\(\\bar{x}\\) and variance \\(s^2\\): Then the posterior mean is \\[ \\frac{1}{\\frac{1}{\\sigma_0^2}+\\frac{n}{\\sigma^2}} \\left( \\frac{\\mu_0}{\\sigma_0^2}+ \\frac{\\sum_{i=1}^{n}{x_i}}{\\sigma^2}\\right) \\] And the posterior variance is: \\[ \\left( \\frac{1}{\\sigma_0^2} +\\frac{n}{\\sigma^2} \\right)^{-1} \\] Questions: Is that math there just to scare you? (hint: no) What happens when the prior variance, \\(\\sigma^2_0\\) , is very large? What happens when the sample size, \\(n\\), is very large? Yes, that is correct. When the sample size and/or the prior variance is large, the influence of the prior diminishes to 0. See also https://ocw.mit.edu/courses/mathematics/18-05-introduction-to-probability-and-statistics-spring-2014/readings/MIT18_05S14_Reading15a.pdf and https://en.wikipedia.org/wiki/Conjugate_prior 10.1.4 Uniformative / Weak / Flat Priors It is common to use what is known as a ‘noninformative’ or ‘flat’ prior. This is often the easiest approach, and is roughly defined by the fact that the priors have no influence on the model. Some common non-informative priors include a standard normal with large variance, such as \\(N(0, 10^4)\\) or a wide uniform distribution - such as \\(U(-10^4, 10^4)\\). Discussion: If you were setting a prior on the size of a fish, what would your prior be? That was a trick question - is size measured as mass or length? Hint: Consider a spherical fish with radius 1cm and density of 1g/ml. Recall \\(V=\\frac{4}{3}\\pi r^3\\) When are informative priors useful? length &lt;- runif(100000, -10000, 10000) mass &lt;- 4/3 * pi * (length / 2) ^ 3 par(mfrow=c(1,2)) hist(length, probability = TRUE, breaks = 100) hist(mass, probability = TRUE, breaks = 100) Correct, even a non-informative prior or ‘flat’ prior on length is not so flat on a different scale. Consider other transformations. What else do you notice about the range of values? Correct, most of the measurements that we make are greater than zero. At a minimum, it is useful to have a prior with a lower bound at zero. These include the log-Normal, Gamma, Weibull, and many other distributions. But as soon as you specify a prior distribution, you are imposing your understanding on the model. This is okay! This is The Way! In conclusion, there really is no such thing as a non-informative prior. However, it is often vastly easier to specify a weak prior than to go through the trouble of justifying an informative prior. 10.1.5 Regularizing priors Regularization priors are relatively non-informative, but on a similar scale as the data. These provide a way to assign 0 probability to impossible values (e.g. a boundary at zero) and to down weight extreme outlines. 10.1.6 Informative Priors Informative priors are particularly useful in contexts with limited available data. In many cases, it will be possible for an expert to use what is already known about a variable to specify a more informative prior. In the ideal case, a posterior from a previous study can be used as the prior for the subsequent study. This is the first step toward iterative forecasting - updating a prediction as new information becomes available. In practice, however, it is often wise to inflate the variance to account for differences across systems - the specific study system (Delta) and what is generally known about freshwater systems. There are many sources of information from which you can specify priors, including: Expert knowledge, including biophysical constraints, logical bounds, or reasonable values based on experience (what are the upper and lower bounds for the length of a mouse?) Lots of data from prior studies on the same system. A little bit of data. A lot or a little bit of data, but from a related system Posterior from a related model, or from the same model at a prior time-step. Prior sensitivity It is prudent to test the sensitivity of your model to your prior assumptions. Having a model that is sensitive to priors is OK, especially when there is a strong rationale and support from data. However, it is necessary to understand how the use of an informative prior affects your posterior estimates. It is very common when using strong priors to find that the MCMC chains do not converge, because the posteriors exist where the priors have very low probaility. This often leads you to uncover differences between how you and the computer understand your model (what you think the code says and what it actually says); it can also point to errors in the data (often related to scale, or unexpected factors that differ), and other assumptions. If applicable, you can plot the data against the prior on Y. Plot the data against The easiest way to do this is to plot the prior PDFs and posterior histograms, and to compare the prior and posterior variances of each parameter. If the ratio of posterior:prior SD &gt; 0.1, you have an informative prior and you should be careful. Think of this in the same way that you think of model specification. You can compare model posteriors fit with different priors in the same way that you can compare models with different structures or parameters, both visually and statistically. 10.1.7 Generating Priors based or Expert knowledge: Package rriskDistributions The rriskDistributions is useful for estimating priors. Individual functions for each distribution such as get.&lt;somedist&gt;.par include diagnostic plots that compare chosen points to cdf. As an example, compute the parameters of a Gamma distribution that fits a median of 2.5 and has a 95%CI of [1, 10]: library(rriskDistributions) get.gamma.par(p = c(0.025, 0.50, 0.975), q = c(1, 2.5, 10), tol = 0.1) ## The fitting procedure &#39;L-BFGS-B&#39; was successful! ## $par ## [1] 6.300745 2.388508 ## ## $value ## [1] 6.942286e-05 ## ## $counts ## function gradient ## 26 26 ## ## $convergence ## [1] 0 ## ## $message ## [1] &quot;CONVERGENCE: REL_REDUCTION_OF_F &lt;= FACTR*EPSMCH&quot; ## shape rate ## 6.300745 2.388508 The function fit.pecr provides a GUI to explore the fits of a range of distributions, e.g.: fit.perc(p = c(0.1, 0.5, 0.9), q = c(30, 60, 90), tolConv = 0.1) Web based elicitation tool http://optics.eee.nottingham.ac.uk/match/uncertainty.php# (Morris et al 2013) Activity: Create your own priors Work with a partner in your project group Choose a parameter in one of the models that you are developing (e.g. growth rate of a fish population, lag between flooding event and peak phytoplankton concentration); Write down what you know about this based on your experience. Start with plausible ranges (max, min) then location of tails - 95% CI. Estimate most likely values and central tendencies (median, mode) last. Choose one of the tools above and generate a set of flat, weak / regularizing, and a strong prior. 10.1.8 Statistical fitting to data More formal, data driven examples are provided in LeBauer et al 2013. Not always worth the trouble. Some code in https://github.com/PecanProject/pecan/blob/develop/modules/priors/vignettes/priors_demo.Rmd Maximum likelihood fitting of parametric distributions to related data Bayesian ‘posterior prediction’ of an unobserved class for which data has been collected from other classes. model{ for (k in 1:length(Y)){ Y[k] ~ dnorm(beta.ft[ft[k]], tau.y[k])T(0,) tau.y[k] &lt;- prec.y*n[k] u1[k] &lt;- n[k]/2 u2[k] &lt;- n[k]/(2*prec.y) obs.prec[k] ~ dgamma(u1[k], u2[k]) } for (f in 1:5){ beta.ft[f] ~ dnorm(0, tau.ft) } tau.ft ~ dgamma(0.1, 0.1) prec.y ~ dgamma(0.1, 0.1) sd.y &lt;- 1 / sqrt(prec.y) ## estimating posterior predictive for new C4 species pi.pavi &lt;- Y[length(Y)] diff &lt;- beta.ft[1] - beta.ft[2] } 10.1.9 References and further reading David E. Morris, Jeremy E. Oakley, John A. Crowe, A web-based tool for eliciting probability distributions from experts, Environmental Modelling &amp; Software, Volume 52, February 2014, Pages 1-4, ISSN 1364-8152, http://dx.doi.org/10.1016/j.envsoft.2013.10.010. Gelman, Lawrence, et al “Prior choice recommendations” Stan Community Wiki https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations "],["session-11-missing-data.html", "11 Session 11: Missing Data 11.1 Missing Data", " 11 Session 11: Missing Data 11.1 Missing Data 11.1.1 General Concepts a frequent problem can bias estimates of parameters and their variances lots of different ways to handle it too often, solution is to throw out data - easiest, and easiest to justify. But I am going review a few examples of how to get around missing data. 11.1.2 Where does missing data come from (or go?) Types of missing data 11.1.3 What to do about missing data How to record missing data - what does NULL mean? What does NA mean? - This is almost never specified. Some options: - observation was not recorded, or was recorded and not entered - data was collected and entered, but later found to be suspect, and removed - the data is in my notebook / I can’t be bothered to enter it - there was nothing to measure; a value here would not make sense 11.1.4 Types of missing data The first two can be safely removed (Gelman and Hill 2006) - Missing completely at random. A useful assumption; difficult to prove. - Missing at random. Missingness depends on observed variables - e.g. one species of fish can be observed but not caught and measured, or a sensor only works when the temperature is below some threshold. - Missing not at random - Missing but depends on unobserved variable - Missing but depends on the variable itself 11.1.5 Approaches If there are a few missing data points (&lt;5-10%) - delete records with missing data - replace missing data If there are more, this can lead to bias. - MICE - Missing data in Bayesian models 11.1.5.1 MICE: Multiple Imputation by Chained Equations This is one of the most commonly used approaches, because it is very powerful. A few limitations of the MICE approach include: it requires the assumption that data are missing completely at random. Further, it is based on empirical analysis rather than theory. Algorithm: - create multiple copies of data - impute missing values - use the distribution of a variable to impute plausible values for the missing data - perform analysis on the values - combine results See Rubin 1987 and White et al 2011 for background on the MICE algorithm. 11.1.5.2 Interpolation There are a variety of methods for interpolating missing data in time series. This is frequently used for environmental sensors - weather stations, eddy covariance towers, temperature or soil moisture data. Lets look at an example. This dataset doesn’t have any missing data, so we will make some. library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following objects are masked from &#39;package:base&#39;: ## ## date, intersect, setdiff, union library(dplyr) library(imputeTS) ## Registered S3 method overwritten by &#39;quantmod&#39;: ## method from ## as.zoo.data.frame zoo library(forecast) library(ggplot2) theme_set(theme_bw()) mac_daymet &lt;- readr::read_csv(&#39;../data/mac_daymet.csv&#39;) %&gt;% filter(year(date) &gt; 2016) ## Rows: 7665 Columns: 7 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (6): precip, tmax, tmin, tmean, trange, vpd ## date (1): date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. mac_nas &lt;- readr::read_csv(&#39;../data/mac_nas.csv&#39;) ## Rows: 1460 Columns: 7 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## dbl (6): precip, tmax, tmin, tmean, trange, vpd ## date (1): date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. ggplot(data = mac_daymet) + geom_point(aes(date, tmean)) ggplot() + geom_point(data = mac_daymet, aes(date, tmean), color = &#39;red&#39;, size = 1)+ geom_point(data = mac_nas, aes(date, tmean), size = 1) ## Warning: Removed 272 rows containing missing values (geom_point). mac_nojja &lt;- mac_daymet %&gt;% mutate(tmean = ifelse(month(date) %in% 6:8 &amp; year(date) == 2020, NA, tmean)) ggplot() + geom_point(data = mac_daymet, aes(date, tmean), color = &#39;red&#39;, size = 1)+ geom_point(data = mac_nojja, aes(date, tmean), size = 1) ## Warning: Removed 92 rows containing missing values (geom_point). Now, what do we do? Well, lets look for a related variable - pairs(mac_daymet %&gt;% filter(year(date) == 2020) %&gt;% select(precip, tmin, tmean, vpd, date)) It looks like we can do a decent job of predicting tmean from tmin (or tmax for that matter … lets pretend that we don’t know the relationship tmean = (tmin + tmean) / 2 or have the ability to estimate ) tmean_model &lt;- lm(tmean ~ tmin, data = mac_nas) tmean_model2 &lt;- lm(tmean ~ tmin + precip, data = mac_nas) tmean_model3 &lt;- lm(tmean ~ vpd + tmin, data = mac_nas) tmean_model4 &lt;- lm(tmean ~ vpd + tmin + precip, data = mac_nas) summary(tmean_model4) ## ## Call: ## lm(formula = tmean ~ vpd + tmin + precip, data = mac_nas) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.9949 -0.9598 0.0878 1.0588 5.2823 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.8403651 0.0996198 88.741 &lt; 2e-16 *** ## vpd -0.0018815 0.0001377 -13.663 &lt; 2e-16 *** ## tmin 1.0703254 0.0077675 137.795 &lt; 2e-16 *** ## precip -0.1242346 0.0168094 -7.391 2.75e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.5 on 1184 degrees of freedom ## (272 observations deleted due to missingness) ## Multiple R-squared: 0.9687, Adjusted R-squared: 0.9686 ## F-statistic: 1.221e+04 on 3 and 1184 DF, p-value: &lt; 2.2e-16 anova(tmean_model, tmean_model2, tmean_model3, tmean_model4) ## Analysis of Variance Table ## ## Model 1: tmean ~ tmin ## Model 2: tmean ~ tmin + precip ## Model 3: tmean ~ vpd + tmin ## Model 4: tmean ~ vpd + tmin + precip ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 1186 3311.5 ## 2 1185 3086.1 1 225.48 100.150 &lt; 2.2e-16 *** ## 3 1185 2788.7 0 297.34 ## 4 1184 2665.7 1 122.98 54.624 2.751e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ### another way to check if we need the full model MASS::stepAIC(tmean_model4) ## Start: AIC=968.15 ## tmean ~ vpd + tmin + precip ## ## Df Sum of Sq RSS AIC ## &lt;none&gt; 2666 968.1 ## - precip 1 123 2789 1019.7 ## - vpd 1 420 3086 1140.1 ## - tmin 1 42750 45416 4334.6 ## ## Call: ## lm(formula = tmean ~ vpd + tmin + precip, data = mac_nas) ## ## Coefficients: ## (Intercept) vpd tmin precip ## 8.840365 -0.001882 1.070325 -0.124235 ### ok. both RSS and AIC say &#39;keep them all&#39;! nas &lt;- which(is.na(mac_nas$tmean)) pred_tmean &lt;- predict(object = tmean_model4, newdata = mac_nas[nas,]) mac_pred &lt;- mac_nas mac_pred$tmean[nas] &lt;- pred_tmean plot(tmean_model4) plot(pred_tmean, mac_daymet$tmean[nas]) + lines(0:40,0:40, lty = 2) hist(pred_tmean - mac_daymet$tmean[nas], breaks = 20) The book ’forecating practices and principles: https://otexts.com/fpp2/missing-outliers.html ggplot_na_imputations(x_with_na = mac_nojja$tmean, x_with_imputations = mac_pred$tmean, x_with_truth = mac_daymet$tmean ) ggplot_na_distribution(mac_nas$tmean, x_axis_labels = mac_nas$date) interp &lt;- na.interp(mac_nas$tmean) plot(mac_daymet$tmean, interp) interp_jjas &lt;- na.interp(mac_nojja$tmean) plot(mac_daymet$tmean, interp_jjas) ggplot_na_distribution(mac_nas$tmean, x_axis_labels = mac_nas$date) ggplot_na_distribution(mac_nojja$tmean, x_axis_labels = mac_nojja$date) ggplot_na_intervals(mac_nas$tmean) ggplot_na_intervals(mac_nojja$tmean) Gap Filling - weather, time series imp &lt;- na_interpolation(mac_nas, option = &#39;spline&#39;) ggplot_na_imputations(x_with_na = mac_nas$tmean, x_with_imputations = imp$tmean, x_with_truth = mac_daymet$tmean ) imp &lt;- na_interpolation(mac_nojja, option = &#39;stine&#39;) ggplot_na_imputations(x_with_na = mac_nojja$tmean, x_with_imputations = imp$tmean, x_with_truth = mac_daymet$tmean ) Your turn: try some different aproaches to missing data imputation: replace with overall mean na_mean replace with moving average na_ma replace with … random draws? na_random my_ts &lt;- function(x){ ts(x, start = c(2017, 1), end = c(2020, 365), deltat = 1/365) } imp &lt;- na_seasplit(my_ts(mac_nojja$tmean)) ggplot_na_imputations(x_with_na = my_ts(mac_nojja$tmean), x_with_imputations = imp, x_with_truth = my_ts(mac_daymet$tmean )) 11.1.5.3 Bayesian Imputation The brms package also provides utilities for handling missing data, including prior to model fitting using MICE and related methods as well as during model fitting. These are explained in the vignette by Brukner 2021 “Handle Missing Values with brms” and the online version of Statistical Rethinking Chapter 14. The same can be done using JAGS, it is possible to estimate variables as model parameters during model fitting. With both JAGS and brms, it is necessary to specify a model for any variable with data being estimated (e.g. predictor variables must be explictly modeled as a response, even if drawn directly from a prior). It is possible to use the MICE algorithm in Bayesian analysis. The disadvantage of using MICE with many Bayesian methods such as MCMC is that it increases the amount of computing time as a linear function of the number of datasets with imputed values (often 5-20x). Since many models can take hours or days to fit, this is an important limitation to consider. 11.1.5.4 Estimating SE from previously published findings to support Meta-analysis A tangent: Meta-analysis itself can be viewed as a missing data problem. Combining information from two studies that were conducted in different conditions or treatment levels, I am trying to make inference about a single variable such as response rate even if the studies measured different responses. However, that is not the focus here. Very often, meta-analysis models require measures of variance around a particular treatment response in order to weight the studies. However, the original studies have different goals than the meta-analysis, so these values may not be reported. A standard convention is to reject studies that do not have the required estimates of standard error. However, this can limit inference. It can also motivate sharing data - that would reduce the need for such laborious and uncertain approximations. Some methods for estimating SE from other statistics are summarized in LeBauer 2020 (developed at the time of LeBauer et al 2013 but not given a doi until 2020), before the text Koricheva et al 2013 gave a related perspective. LeBauer et al 2013 also provide examples for estimating these statistics even where they can’t be estimated while fitting a meta-analysis. 11.1.6 References Gelman and Hill 2006. Ch 25: Missing Data Imputation in “Data Analysis Using Regression and Multilevel/Hierarchical Models.” Cambridge University Press http://www.stat.columbia.edu/~gelman/arm/missing.pdf Su, Y.-S., Gelman, A., Hill, J., &amp; Yajima, M. (2011). Multiple Imputation with Diagnostics (mi) in R: Opening Windows into the Black Box. Journal of Statistical Software, 45(2), 1–31. https://doi.org/10.18637/jss.v045.i02 https://www.jstatsoft.org/article/view/v045i02 Rubin DB (1987). Multiple Imputation for Nonresponse in Surveys. John Wiley &amp; Sons, New York. White, Ian R., Patrick Royston, and Angela M. Wood. “Multiple imputation using chained equations: issues and guidance for practice.” Statistics in medicine 30.4 (2011): 377-399. Steffen Moritz and Thomas Bartz-Beielstein (2017) imputeTS: Time Series Missing Value Imputation in R. The R Journal (2017) 9:1, pages 207-218. https://journal.r-project.org/archive/2017/RJ-2017-009/index.html CRAN Task View: Missing Data https://cran.r-project.org/web/views/MissingData.html Koricheva, J., Gurevitch, J., &amp; Mengersen, K. (Eds.). (2013). Handbook of Meta-analysis in Ecology and Evolution. Princeton University Press. http://www.jstor.org/stable/j.ctt24hq6n LeBauer, David S., et al. “Facilitating feedbacks between field measurements and ecosystem models.” Ecological Monographs 83.2 (2013): 133-154. LeBauer, David. “Transforming ANOVA and Regression statistics for Meta-analysis.” Authorea Preprints (2020). https://doi.org/10.22541/au.158359749.96662550 "],["session-11-timeseries.html", "12 Session 11: Timeseries", " 12 Session 11: Timeseries "],["session-13-time-series-and-forecasting.html", "13 Session 13: Time series and forecasting", " 13 Session 13: Time series and forecasting "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
